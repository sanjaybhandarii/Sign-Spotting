{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["!pip install pytorchvideo"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"outputs":[],"source":["import torch\n","import numpy as np\n","from torch.utils.data import (\n","    Dataset,\n","    DataLoader,\n",") \n","import pickle\n","\n","import os\n","\n","import math\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","from torchvision.transforms import Compose, Lambda, Grayscale,Normalize\n","from torchvision.transforms._transforms_video import CenterCropVideo\n","from pytorchvideo.data.encoded_video import EncodedVideo\n","from pytorchvideo.transforms import (\n","    ApplyTransformToKey,\n","    UniformTemporalSubsample,\n",")\n","\n","from tqdm import tqdm\n","\n","from collections import OrderedDict\n","\n","import torch.optim as optim\n","\n","\n","\n","class SignDataset(Dataset):\n","    def __init__(self,x,y):\n","        self.x = x\n","        self.y = y\n","\n","\n","    def __len__(self):\n","\n","        return len(self.y)\n","\n","        # length = 0\n","        # with open(self.file, 'rb') as f:\n","        #     data = pickle.load(f)\n","\n","        # for x in data:\n","        #     length += len(data[x])\n","        # return length\n","\n","\n","    def __getitem__(self, index):\n","        return self.x[index], self.y[index]\n","        "]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["IMAGE_HEIGHT = 720\n","IMAGE_WIDTH = 800\n","IMAGE_CHANNEL = 1\n","NUM_FRAMES = 25\n","NUM_CLASSES = 60\n","\n","\n","\n","inputs =[] #x\n","classes = [] #y\n","\n","def transform_data(x, mean, std):\n","    \n","    transform =  ApplyTransformToKey(\n","        key=\"video\",\n","        transform=Compose(\n","            [\n","\n","                Lambda(lambda x: x.permute(1,0,2,3)),#(frames(depth), channel, height, width) -> (channel, frames(depth), height, width)\n","\n","                UniformTemporalSubsample(NUM_FRAMES),\n","                Lambda(lambda x: x.permute(1,0,2,3)),#(frames(depth), channel, height, width)\n","                Lambda(lambda x: x/255.0),\n","                \n","                Normalize((mean,), (std,)),\n","\n","                CenterCropVideo([720,800]),\n","                Lambda(lambda x: x.permute(1,0,2,3)),#(channel, frames(depth), height, width)\n","\n","            ]\n","\n","        ),\n","    )\n","    \n","    return transform(x)\n","\n","\n","\n","    \n","\n","def get_data_info(f):\n","    for line in f:\n","        a = line.split(',')\n","        yield a\n","        \n","\n","\n","def load_dataloader(batch_size):\n","    with open('../input/signdataset/sign/MSSL_Train_Set/TRAIN/MSSL_TRAIN_SET_GT.pkl', 'rb') as f:\n","        data = pickle.load(f)\n","\n","\n","# keys are files so iterate only limited files due to memory limitations.\n","    for key in list(data.keys())[:5]:\n","        filename = key\n","        print(\"file\",filename)\n","        video = EncodedVideo.from_path(\"../input/signdataset/sign/MSSL_Train_Set/TRAIN/MSSL_TRAIN_SET_VIDEOS_ELAN/\"+filename+\".mp4\")\n","    # file functions\n","\n","        for x in data[key]:\n","            classes.append(x[0])\n","            start_time = x[1]\n","            end_time = x[2]\n","   #give path\n","            \n","    \n","            \n","            \n","            video_data = video.get_clip(start_sec=float(start_time)/1000.0, end_sec=float(end_time)/1000.0)\n","\n","            \n","            video_data[\"video\"] = Grayscale(num_output_channels=1)((video_data[\"video\"]).permute(1,0,2,3))\n","#             video_data[\"video\"] = video_data[\"video\"]/255\n","            #print(video_data[\"video\"].shape)\n","            \n","            std, mean = torch.std_mean(video_data[\"video\"])\n","            std = std/255.0\n","            mean = mean/255.0\n","        \n","            \n","            \n","            video_data = transform_data( video_data, mean, std)\n","\n","        # Move the inputs to the desired device\n","            inputs.append(video_data[\"video\"])\n","\n","    signds = SignDataset(inputs, classes)\n","    dataloader = DataLoader(signds, batch_size=batch_size, shuffle=True, num_workers=1)\n","\n","    return dataloader\n","        \n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["\n","\n","\n","\n","class conv_3d(nn.Module):\n","    def __init__(self):\n","        super(conv_3d, self).__init__()\n","        self.conv1 = nn.Sequential(\n","            nn.Conv3d(1, 64, kernel_size=5, padding=1),\n","            nn.ReLU(),\n","            nn.MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2)))\n","        \n","        self.conv2 = nn.Sequential(\n","            nn.Conv3d(64, 128, kernel_size=3, padding=1),\n","            nn.ReLU(),\n","            nn.MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2)))\n","        \n","\n","        self._features = nn.Sequential(\n","            self.conv1,\n","            self.conv2\n","        )\n","\n","\n","    def forward(self, x):\n","        return self._features(x)# batch size, num channels,frames,  height, width\n","\n","\n","\n","\n","class BasicBlock(nn.Module):\n","    def __init__(self, in_planes, out_planes, dropRate=0.0):\n","        super(BasicBlock, self).__init__()\n","        self.bn1 = nn.BatchNorm2d(in_planes)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.conv1 = nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=1,\n","                               padding=1, bias=False)\n","        self.droprate = dropRate\n","    def forward(self, x):\n","        out = self.conv1(self.relu(self.bn1(x)))\n","        if self.droprate > 0:\n","            out = F.dropout(out, p=self.droprate, training=self.training)\n","        return torch.cat([x, out], 1)\n","\n","class BottleneckBlock(nn.Module):\n","    def __init__(self, in_planes, out_planes, dropRate=0.0):\n","        super(BottleneckBlock, self).__init__()\n","        inter_planes = out_planes * 4\n","        self.bn1 = nn.BatchNorm2d(in_planes)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.conv1 = nn.Conv2d(in_planes, inter_planes, kernel_size=1, stride=1,\n","                               padding=0, bias=False)\n","        self.bn2 = nn.BatchNorm2d(inter_planes)\n","        self.conv2 = nn.Conv2d(inter_planes, out_planes, kernel_size=3, stride=1,\n","                               padding=1, bias=False)\n","        self.droprate = dropRate\n","    def forward(self, x):\n","        out = self.conv1(self.relu(self.bn1(x)))\n","        if self.droprate > 0:\n","            out = F.dropout(out, p=self.droprate, inplace=False, training=self.training)\n","        out = self.conv2(self.relu(self.bn2(out)))\n","        if self.droprate > 0:\n","            out = F.dropout(out, p=self.droprate, inplace=False, training=self.training)\n","        return torch.cat([x, out], 1)\n","\n","class TransitionBlock(nn.Module):\n","    def __init__(self, in_planes, out_planes, dropRate=0.0):\n","        super(TransitionBlock, self).__init__()\n","        self.bn1 = nn.BatchNorm2d(in_planes)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.conv1 = nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=1,\n","                               padding=0, bias=False)\n","        self.droprate = dropRate\n","    def forward(self, x):\n","        out = self.conv1(self.relu(self.bn1(x)))\n","        if self.droprate > 0:\n","            out = F.dropout(out, p=self.droprate, inplace=False, training=self.training)\n","        return F.avg_pool2d(out, 2)\n","\n","class DenseBlock(nn.Module):\n","    def __init__(self, nb_layers, in_planes, growth_rate, block, dropRate=0.0):\n","        super(DenseBlock, self).__init__()\n","        self.layer = self._make_layer(block, in_planes, growth_rate, nb_layers, dropRate)\n","    def _make_layer(self, block, in_planes, growth_rate, nb_layers, dropRate):\n","        layers = []\n","        for i in range(nb_layers):\n","            layers.append(block(in_planes+i*growth_rate, growth_rate, dropRate))\n","        return nn.Sequential(*layers)\n","    def forward(self, x):\n","        return self.layer(x)\n","\n","class DenseNet3(nn.Module):\n","    def __init__(self, depth=10, num_classes=60, growth_rate=12,\n","                 reduction=0.5, bottleneck=True, dropRate=0.4):\n","        super(DenseNet3, self).__init__()\n","        in_planes = 2 * growth_rate\n","        n = (depth - 4) / 3\n","        if bottleneck == True:\n","            n = n/2\n","            block = BottleneckBlock\n","        else:\n","            block = BasicBlock\n","        n = int(n)\n","        # 1st conv before any dense block\n","        self.conv1 = nn.Conv2d(128, in_planes, kernel_size=3, stride=1,\n","                               padding=1, bias=False)\n","        # 1st block\n","        self.block1 = DenseBlock(n, in_planes, growth_rate, block, dropRate)\n","        in_planes = int(in_planes+n*growth_rate)\n","        self.trans1 = TransitionBlock(in_planes, int(math.floor(in_planes*reduction)), dropRate=dropRate)\n","        in_planes = int(math.floor(in_planes*reduction))\n","        # 2nd block\n","        self.block2 = DenseBlock(n, in_planes, growth_rate, block, dropRate)\n","        in_planes = int(in_planes+n*growth_rate)\n","        self.trans2 = TransitionBlock(in_planes, int(math.floor(in_planes*reduction)), dropRate=dropRate)\n","        in_planes = int(math.floor(in_planes*reduction))\n","        # 3rd block\n","        self.block3 = DenseBlock(n, in_planes, growth_rate, block, dropRate)\n","        in_planes = int(in_planes+n*growth_rate)\n","        # global average pooling and classifier\n","        self.bn1 = nn.BatchNorm2d(in_planes)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.fc = nn.Linear(in_planes, num_classes)\n","        self.in_planes = in_planes\n","\n","        for m in self.modules():\n","            if isinstance(m, nn.Conv2d):\n","                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n","                m.weight.data.normal_(0, math.sqrt(2. / n))\n","            elif isinstance(m, nn.BatchNorm2d):\n","                m.weight.data.fill_(1)\n","                m.bias.data.zero_()\n","            elif isinstance(m, nn.Linear):\n","                m.bias.data.zero_()\n","    def forward(self, x):\n","        out = self.conv1(x)\n","        \n","        out = self.trans1(self.block1(out))\n","        \n","        out = self.trans2(self.block2(out))\n","        \n","        out = self.block3(out)\n","        \n","        out = self.relu(self.bn1(out))\n","        \n","        out = F.avg_pool2d(out, 3)\n","        \n","        \n","        return out\n","        \n","        \n","\n","\n","def flatten(t):\n","    t = t.reshape(1, -1)\n","    t = t.squeeze()\n","    return t\n","  \n","class TimeDistributed(nn.Module):\n","    def __init__(self, module, batch_first=True):\n","        super(TimeDistributed, self).__init__()\n","        self.module = module\n","        self.batch_first = batch_first\n","\n","    def forward(self, x):\n","        \n","        x = x.permute(0,1,3,4,2)# (batch, channels, height, width, frames)\n","        tList = [flatten(self.module(m)) for m in torch.unbind(x, dim=4) ]\n","        y = torch.stack(tList, dim=0)\n","        # We have to reshape Y\n","        if self.batch_first:\n","            y = y.contiguous().view(x.size(0), -1,y.size(-1))  # (samples, timesteps, output_size)\n","            \n","        else:\n","            y = y.view(-1, x.size(0), y.size(-1))  # (timesteps, samples, output_size)\n","            \n","        return y\n","    \n","\n","class block(nn.Module):\n","    def __init__(self,ni):\n","        super(block, self).__init__()\n","        self.conv1 = nn.Conv1d(ni, ni, 1)\n","        self.conv2 = nn.Conv1d(ni, ni, 3, 1, 1)\n","\n","    def forward(self,x):\n","        residual = x\n","        out = F.relu(self.conv1(x))\n","        out = F.relu(self.conv2(out))\n","       \n","        \n","        \n","        out += residual\n","        \n","        \n","        \n","        return out\n","    \n","class SEQ(nn.Module):\n","    def __init__(self, input_size, hidden_size1):\n","        super(SEQ, self).__init__()\n","        self.input_size = input_size\n","        self.hidden_size = hidden_size1\n","\n","        self.c1 = block(input_size)\n","        self.p1 = nn.AvgPool2d(2)\n","        self.c2 = block(hidden_size1)\n","        self.p2 = nn.AvgPool2d(2)\n","        \n","\n","    def forward(self, inputs):\n","      \n","        #print(inputs.shape)\n","\n","        # Run through Conv1d and Pool1d layers\n","        c = self.c1(inputs)\n","        p = self.p1(c)\n","        c = self.c2(p)\n","        p = self.p2(c)\n","        out = F.relu(p)\n","        out = out.view(1,-1)\n","        return out\n","\n","\n","\n","\n","\n","\n","\n","\n","  "]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["\n","\n","\n","n_classes = 60\n","\n","model = nn.Sequential(OrderedDict([\n","    ('frontend', conv_3d()),\n","    ('features', TimeDistributed(DenseNet3())),\n","    ('backend', SEQ(input_size=5, hidden_size1=2)),\n","    ('fc', nn.Sequential( nn.Dropout(p=0.5), nn.Linear(1512, 378), nn.Linear(378,60)))\n","]))\n","\n","\n","\n","\n","\n","# specify loss function (categorical cross-entropy)\n","criterion = nn.CrossEntropyLoss()\n","# specify optimizer and learning rate\n","optimizer = optim.SGD(\n","  [\n","        {\"params\": model.fc.parameters(), \"lr\": 1e-3},\n","        {\"params\": model.features.parameters(), \"lr\": 1e-5},\n","        {\"params\": model.backend.parameters(), \"lr\": 1e-5},\n","        {\"params\": model.frontend.parameters(), \"lr\": 1e-4},\n","  ],\n","  momentum = 0.9\n",")\n","print('Number of model parameters: {}'.format(sum([p.data.nelement() for p in model.parameters()])))\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","# state = torch.load(\"../input/sign-classification/model_optimizer.pt\")\n","# model.load_state_dict(state['model_state_dict'])\n","model.half()\n","model.cuda()\n","\n","#optimizer.load_state_dict(state['optimizer_state_dict'])\n","\n","\n","def train(model, device, train_loader, optimizer, criterion, epoch):\n","    \n","    \n","    model.train()\n","    \n","    \n","    \n","    \n","    \n","    for epoch in range(epoch):\n","        correct = 0\n","        num_samples = 0\n","        train_loss = 0\n","        \n","        for batch_idx, (data, target) in enumerate(train_loader):\n","            \n","            data = data.to(device)\n","            target = (target).to(device)\n","            \n","    \n","    \n","            optimizer.zero_grad()\n","            output = model(data.half())\n","            \n","            loss = criterion(output, target)\n","            loss.backward()\n","            optimizer.step()\n","            \n","            train_loss += loss.item()\n","            \n","            pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n","            num_samples += pred.shape[0]\n","            correct += int(pred==target)\n","            \n","        \n","        train_loss /= num_samples\n","    \n","        print('Epoch: {} , Training Accuracy: {}/{} ({:.0f}%) Training Loss: {:.6f}'.format(\n","                epoch, correct, num_samples,\n","                100. * correct / num_samples, train_loss))\n","    torch.save({\n","            'model_state_dict': model.state_dict(),\n","            'optimizer_state_dict': optimizer.state_dict()}, \"./model_optimizer.pt\")\n","        \n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","dataloader = load_dataloader(batch_size=1)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["train(model,device,dataloader,optimizer,criterion,25)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"nbformat":4,"nbformat_minor":4}
