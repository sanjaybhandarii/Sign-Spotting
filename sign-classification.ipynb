{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install pytorchvideo","metadata":{"execution":{"iopub.status.busy":"2022-05-23T04:37:57.566206Z","iopub.execute_input":"2022-05-23T04:37:57.566472Z","iopub.status.idle":"2022-05-23T04:38:18.297661Z","shell.execute_reply.started":"2022-05-23T04:37:57.566402Z","shell.execute_reply":"2022-05-23T04:38:18.296811Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting pytorchvideo\n  Downloading pytorchvideo-0.1.5.tar.gz (132 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.7/132.7 KB\u001b[0m \u001b[31m299.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting fvcore\n  Downloading fvcore-0.1.5.post20220512.tar.gz (50 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.1/50.1 KB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting av\n  Downloading av-9.2.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (28.2 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m28.2/28.2 MB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting parameterized\n  Downloading parameterized-0.8.1-py2.py3-none-any.whl (26 kB)\nCollecting iopath\n  Downloading iopath-0.1.9-py3-none-any.whl (27 kB)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.7/site-packages (from pytorchvideo) (2.5)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from fvcore->pytorchvideo) (1.21.6)\nRequirement already satisfied: yacs>=0.1.6 in /opt/conda/lib/python3.7/site-packages (from fvcore->pytorchvideo) (0.1.8)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from fvcore->pytorchvideo) (6.0)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from fvcore->pytorchvideo) (4.63.0)\nRequirement already satisfied: termcolor>=1.1 in /opt/conda/lib/python3.7/site-packages (from fvcore->pytorchvideo) (1.1.0)\nRequirement already satisfied: Pillow in /opt/conda/lib/python3.7/site-packages (from fvcore->pytorchvideo) (9.0.1)\nRequirement already satisfied: tabulate in /opt/conda/lib/python3.7/site-packages (from fvcore->pytorchvideo) (0.8.9)\nRequirement already satisfied: portalocker in /opt/conda/lib/python3.7/site-packages (from iopath->pytorchvideo) (2.4.0)\nRequirement already satisfied: decorator>=4.3.0 in /opt/conda/lib/python3.7/site-packages (from networkx->pytorchvideo) (5.1.1)\nBuilding wheels for collected packages: pytorchvideo, fvcore\n  Building wheel for pytorchvideo (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for pytorchvideo: filename=pytorchvideo-0.1.5-py3-none-any.whl size=188714 sha256=09d8295c15d5176bd7ee43ad6fe964d1a21abd5a8346a07605a6cf0fdd209eff\n  Stored in directory: /root/.cache/pip/wheels/e8/51/05/053b29bac2400cbbae2fb7cfc41afd280d627bca7c9363ca80\n  Building wheel for fvcore (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for fvcore: filename=fvcore-0.1.5.post20220512-py3-none-any.whl size=61288 sha256=30a5c331283bb42c083c5af4dd2cab8f2867375bf6397de1f65a08f0da9293f6\n  Stored in directory: /root/.cache/pip/wheels/68/20/f9/a11a0dd63f4c13678b2a5ec488e48078756505c7777b75b29e\nSuccessfully built pytorchvideo fvcore\nInstalling collected packages: parameterized, av, iopath, fvcore, pytorchvideo\nSuccessfully installed av-9.2.0 fvcore-0.1.5.post20220512 iopath-0.1.9 parameterized-0.8.1 pytorchvideo-0.1.5\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"start= 1\nend = 10","metadata":{"execution":{"iopub.status.busy":"2022-05-23T04:38:18.299511Z","iopub.execute_input":"2022-05-23T04:38:18.299787Z","iopub.status.idle":"2022-05-23T04:38:18.305133Z","shell.execute_reply.started":"2022-05-23T04:38:18.299741Z","shell.execute_reply":"2022-05-23T04:38:18.304442Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import torch\nimport numpy as np\nfrom torch.utils.data import (\n    Dataset,\n    DataLoader,\n) \nimport pickle\n\n\nimport os\n\nimport math\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nfrom torchvision.transforms import Compose, Lambda, Grayscale,Normalize, CenterCrop,Resize\n#from torchvision.transforms._transforms_video import CenterCropVideo\nfrom pytorchvideo.data.encoded_video import EncodedVideo\nfrom pytorchvideo.transforms import (\n    ApplyTransformToKey,\n    UniformTemporalSubsample,\n)\n\nfrom tqdm import tqdm\n\nfrom collections import OrderedDict\n\nimport torch.optim as optim\n\n\n\n\n\nclass SignDataset(Dataset):\n    def __init__(self,x,y):\n        self.x = x\n        self.y = y\n\n\n    def __len__(self):\n\n        return len(self.y)\n\n        # length = 0\n        # with open(self.file, 'rb') as f:\n        #     data = pickle.load(f)\n\n        # for x in data:\n        #     length += len(data[x])\n        # return length\n\n\n    def __getitem__(self, index):\n        return self.x[index], self.y[index]\n        ","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-23T04:38:18.307804Z","iopub.execute_input":"2022-05-23T04:38:18.308015Z","iopub.status.idle":"2022-05-23T04:38:20.208524Z","shell.execute_reply.started":"2022-05-23T04:38:18.307990Z","shell.execute_reply":"2022-05-23T04:38:20.207791Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"IMAGE_HEIGHT = 720\nIMAGE_WIDTH = 800\nIMAGE_CHANNEL = 1\nNUM_FRAMES = 25\nNUM_CLASSES = 60\n\n\n\ntrain_inputs =[] #x\ntrain_classes = [] #y\nval_inputs = []\nval_classes = []\n\ndef transform_data(x, mean, std):\n    \n    transform =  ApplyTransformToKey(\n        key=\"video\",\n        transform=Compose(\n            [\n\n                Lambda(lambda x: x.permute(1,0,2,3)),#(frames(depth), channel, height, width) -> (channel, frames(depth), height, width)\n\n                UniformTemporalSubsample(NUM_FRAMES),\n                Lambda(lambda x: x.permute(1,0,2,3)),#(frames(depth), channel, height, width)\n                Lambda(lambda x: x/255.0),\n                \n                Normalize((mean,), (std,)),\n\n                CenterCrop([720,854]),\n                Resize([512,610]),\n                Lambda(lambda x: x.permute(1,0,2,3)),#(channel, frames(depth), height, width)\n\n            ]\n\n        ),\n    )\n    \n    return transform(x)\n\n\ndef load_dataloaders(batch_size,start,end):\n    with open('../input/signdataset/sign/MSSL_Train_Set/TRAIN/MSSL_TRAIN_SET_GT.pkl', 'rb') as f:\n        data = pickle.load(f)\n\n\n# keys are files so iterate only limited files due to memory limitations.\n    for key in list(data.keys())[start:end]:\n        filename = key\n        print(\"file\",filename)\n        video = EncodedVideo.from_path(\"../input/signdataset/sign/MSSL_Train_Set/TRAIN/MSSL_TRAIN_SET_VIDEOS_ELAN/\"+filename+\".mp4\")\n    # file functions\n\n        for x in data[key]:\n            train_classes.append(x[0])\n            start_time = x[1]\n            end_time = x[2]\n   #give path\n            \n    \n            \n            \n            video_data = video.get_clip(start_sec=float(start_time)/1000.0, end_sec=float(end_time)/1000.0)\n            #print(video_data[\"video\"].shape)\n\n            \n            video_data[\"video\"] = Grayscale(num_output_channels=1)((video_data[\"video\"]).permute(1,0,2,3))\n#             video_data[\"video\"] = video_data[\"video\"]/255\n            #print(video_data[\"video\"].shape)\n            \n            std, mean = torch.std_mean(video_data[\"video\"])\n            std = std/255.0\n            mean = mean/255.0\n        \n            \n            \n            video_data = transform_data( video_data, mean, std)\n\n        # Move the inputs to the desired device\n            train_inputs.append(video_data[\"video\"])\n\n    signds = SignDataset(train_inputs, train_classes)\n    trainlen = int(len(signds)*0.8)\n    torch.manual_seed(0)\n    \n    train_set, val_test_set = torch.utils.data.random_split(signds, [trainlen, len(signds)-trainlen])\n    trainloader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=2)\n    \n    vallen= int(len(val_test_set)*0.8)\n    val_set, test_set = torch.utils.data.random_split(val_test_set, [vallen, len(val_test_set)-vallen ])\n    valloader = DataLoader(val_set, batch_size=batch_size, shuffle=True, num_workers=2)\n    testloader = DataLoader(test_set, batch_size=batch_size, shuffle=True, num_workers=2)\n    return trainloader, valloader, testloader \n        \n    \n\n","metadata":{"execution":{"iopub.status.busy":"2022-05-23T04:38:20.210610Z","iopub.execute_input":"2022-05-23T04:38:20.210859Z","iopub.status.idle":"2022-05-23T04:38:20.227863Z","shell.execute_reply.started":"2022-05-23T04:38:20.210825Z","shell.execute_reply":"2022-05-23T04:38:20.227221Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"class conv_3d(nn.Module):\n    def __init__(self):\n        super(conv_3d, self).__init__()\n        self.conv1 = nn.Sequential(\n            nn.Conv3d(1, 64, kernel_size=5, padding=1),\n            nn.ReLU(),\n            nn.MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2)))\n        \n        self.conv2 = nn.Sequential(\n            nn.Conv3d(64, 128, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2)))\n        \n\n        self._features = nn.Sequential(\n            self.conv1,\n            self.conv2\n        )\n\n    def forward(self, x):\n        return self._features(x)# batch size, num channels,frames,  height, width\n\nclass BasicBlock(nn.Module):\n    def __init__(self, in_planes, out_planes, dropRate=0.0):\n        super(BasicBlock, self).__init__()\n        self.bn1 = nn.BatchNorm2d(in_planes)\n        self.relu = nn.ReLU(inplace=True)\n        self.conv1 = nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=1,\n                               padding=1, bias=False)\n        self.droprate = dropRate\n    def forward(self, x):\n        out = self.conv1(self.relu(self.bn1(x)))\n        if self.droprate > 0:\n            out = F.dropout(out, p=self.droprate, training=self.training)\n        return torch.cat([x, out], 1)\n\nclass BottleneckBlock(nn.Module):\n    def __init__(self, in_planes, out_planes, dropRate=0.0):\n        super(BottleneckBlock, self).__init__()\n        inter_planes = out_planes * 4\n        self.bn1 = nn.BatchNorm2d(in_planes)\n        self.relu = nn.ReLU(inplace=True)\n        self.conv1 = nn.Conv2d(in_planes, inter_planes, kernel_size=1, stride=1,\n                               padding=0, bias=False)\n        self.bn2 = nn.BatchNorm2d(inter_planes)\n        self.conv2 = nn.Conv2d(inter_planes, out_planes, kernel_size=3, stride=1,\n                               padding=1, bias=False)\n        self.droprate = dropRate\n    def forward(self, x):\n        out = self.conv1(self.relu(self.bn1(x)))\n        if self.droprate > 0:\n            out = F.dropout(out, p=self.droprate, inplace=False, training=self.training)\n        out = self.conv2(self.relu(self.bn2(out)))\n        if self.droprate > 0:\n            out = F.dropout(out, p=self.droprate, inplace=False, training=self.training)\n        return torch.cat([x, out], 1)\n\nclass TransitionBlock(nn.Module):\n    def __init__(self, in_planes, out_planes, dropRate=0.0):\n        super(TransitionBlock, self).__init__()\n        self.bn1 = nn.BatchNorm2d(in_planes)\n        self.relu = nn.ReLU(inplace=True)\n        self.conv1 = nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=1,\n                               padding=0, bias=False)\n        self.droprate = dropRate\n    def forward(self, x):\n        out = self.conv1(self.relu(self.bn1(x)))\n        if self.droprate > 0:\n            out = F.dropout(out, p=self.droprate, inplace=False, training=self.training)\n        return F.avg_pool2d(out, 2)\n    \n    \nclass DenseBlock(nn.Module):\n    def __init__(self, nb_layers, in_planes, growth_rate, block, dropRate=0.0):\n        super(DenseBlock, self).__init__()\n        self.layer = self._make_layer(block, in_planes, growth_rate, nb_layers, dropRate)\n    def _make_layer(self, block, in_planes, growth_rate, nb_layers, dropRate):\n        layers = []\n        for i in range(nb_layers):\n            layers.append(block(in_planes+i*growth_rate, growth_rate, dropRate))\n        return nn.Sequential(*layers)\n    def forward(self, x):\n        return self.layer(x)\n\nclass DenseNet3(nn.Module):\n    def __init__(self, depth=10, num_classes=60, growth_rate=12,\n                 reduction=0.5, bottleneck=True, dropRate=0.4):\n        super(DenseNet3, self).__init__()\n        in_planes = 2 * growth_rate\n        n = (depth - 4) / 3\n        if bottleneck == True:\n            n = n/2\n            block = BottleneckBlock\n        else:\n            block = BasicBlock\n        n = int(n)\n        # 1st conv before any dense block\n        self.conv1 = nn.Conv2d(128, in_planes, kernel_size=3, stride=1,\n                               padding=1, bias=False)\n        # 1st block\n        self.block1 = DenseBlock(n, in_planes, growth_rate, block, dropRate)\n        in_planes = int(in_planes+n*growth_rate)\n        self.trans1 = TransitionBlock(in_planes, int(math.floor(in_planes*reduction)), dropRate=dropRate)\n        in_planes = int(math.floor(in_planes*reduction))\n        # 2nd block\n        self.block2 = DenseBlock(n, in_planes, growth_rate, block, dropRate)\n        in_planes = int(in_planes+n*growth_rate)\n        self.trans2 = TransitionBlock(in_planes, int(math.floor(in_planes*reduction)), dropRate=dropRate)\n        in_planes = int(math.floor(in_planes*reduction))\n        # 3rd block\n        self.block3 = DenseBlock(n, in_planes, growth_rate, block, dropRate)\n        in_planes = int(in_planes+n*growth_rate)\n        # global average pooling and classifier\n        self.bn1 = nn.BatchNorm2d(in_planes)\n        self.relu = nn.ReLU(inplace=True)\n        self.fc = nn.Linear(in_planes, num_classes)\n        self.in_planes = in_planes\n\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n                m.weight.data.normal_(0, math.sqrt(2. / n))\n            elif isinstance(m, nn.BatchNorm2d):\n                m.weight.data.fill_(1)\n                m.bias.data.zero_()\n            elif isinstance(m, nn.Linear):\n                m.bias.data.zero_()\n    def forward(self, x):\n        out = self.conv1(x)\n        \n        out = self.trans1(self.block1(out))\n        \n        out = self.trans2(self.block2(out))\n        \n        out = self.block3(out)\n        \n        out = self.relu(self.bn1(out))\n        \n        out = F.avg_pool2d(out, 3)\n        \n        \n        return out\n        \n        \ndef flatten(t):\n    t = t.reshape(1, -1)\n    t = t.squeeze()\n    return t\n  \nclass TimeDistributed(nn.Module):\n    def __init__(self, module, batch_first=True):\n        super(TimeDistributed, self).__init__()\n        self.module = module\n        self.batch_first = batch_first\n\n    def forward(self, x):\n        \n        x = x.permute(0,1,3,4,2)# (batch, channels, height, width, frames)\n        tList = [flatten(self.module(m)) for m in torch.unbind(x, dim=4) ]\n        y = torch.stack(tList, dim=0)\n        # We have to reshape Y\n        if self.batch_first:\n            y = y.contiguous().view(x.size(0), x.size(4),-1)  # (samples, timesteps, output_size)\n            \n        else:\n            y = y.view(x.size(4), x.size(0), -1)  # (timesteps, samples, output_size)\n        return y\n    \n\n               \n        \n\n\nclass lstm(nn.Module):\n    def __init__(self, input_size, hidden_size):\n        super(lstm, self).__init__()\n        self.hidden_size = hidden_size\n        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)\n\n    def forward(self, x):\n        #print(inputs.shape)\n        # Run through LSTM layer\n        out, _ = self.lstm(x)\n        out = out[:,-1,:]\n        out = out.view(x.size(0),-1)\n        return out\n    \n\n\n\n  ","metadata":{"execution":{"iopub.status.busy":"2022-05-23T04:38:20.230202Z","iopub.execute_input":"2022-05-23T04:38:20.230833Z","iopub.status.idle":"2022-05-23T04:38:20.272348Z","shell.execute_reply.started":"2022-05-23T04:38:20.230799Z","shell.execute_reply":"2022-05-23T04:38:20.271677Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"\ndef test(model, device, loader, mode=\"Validate\"):\n    \n    \n    model.eval()\n\n    correct = 0\n    num_samples = 0\n    \n        \n    for batch_idx, (data, target) in enumerate(loader):\n        with torch.no_grad():    \n            data = data.to(device)\n            target = (target).to(device)\n\n            output = model(data.half())  \n            \n            pred = output.max(1, keepdim=True)[1]# get the index of the max log-probability\n            \n            num_samples += pred.shape[0]\n            \n#             print(\"num_samples:\", num_samples)\n            #print(torch.sum(pred==target))\n            correct += (pred == target).sum().item()\n            #print(\"correct\", correct)\n\n    acc = 100.0 * correct / num_samples\n    \n    print('{} Accuracy: {}/{} ({:.0f}%)'.format(\n                mode,correct, num_samples,\n                100. * correct / num_samples, acc))\n    \ndef trainonval(model, device,validloader, optimizer, scheduler, criterion, epochs):\n\n    \n    model.train()\n    optim.param_groups[0]['lr'] = 1e-2\n    print(\"Training on Validation Set starts\")\n    for epoch in range(epochs):\n        correct = 0\n        num_samples = 0\n        train_loss = 0\n        \n        for batch_idx, (data, target) in enumerate(validloader):\n            \n            data = data.to(device)\n            target = target.to(device)\n\n            optimizer.zero_grad()\n            output = model(data.half())\n            \n            loss = criterion(output, target)\n            loss.backward()\n            optimizer.step()\n            \n            \n            train_loss += loss.item()\n            \n            pred = (output.data).max(1, keepdim=True)[1]# get the index of the max log-probability\n            num_samples += pred.shape[0]\n            correct += torch.sum(pred.data==target)\n            \n        scheduler.step()\n        print(scheduler.get_last_lr())\n        train_loss /= num_samples\n        \n        if (100 * correct / num_samples) >= 90:\n            \n            print('Epoch: {} , Training Accuracy on Val set: {}/{} ({:.0f}%) Training Loss: {:.6f}'.format(\n                epoch+1, correct, num_samples,100. * correct / num_samples, train_loss))\n            test(model, device, testloader, mode = \"Test after Training on validation set\")\n                \n            return model, optimizer\n            \n    \n        print('Epoch: {} , Training Accuracy: {}/{} ({:.0f}%) Training Loss: {:.6f}'.format(\n                epoch+1, correct, num_samples,\n                100. * correct / num_samples, train_loss))\n        \n    return model, optimizer\n\ndef train(model, device, train_loader,validloader,testloader, optimizer,scheduler,criterion, epochs):\n    print(\"Train start\")\n    breakout = False\n#     model.half()\n#     model.cuda()\n    \n    model.train()\n\n    \n    \n    for epoch in range(epochs):\n        correct = 0\n        num_samples = 0\n        train_loss = 0\n        \n        for batch_idx, (data, target) in enumerate(train_loader):\n            \n            data = data.to(device)\n            target = target.to(device)\n\n            optimizer.zero_grad()\n            output = model(data.half())\n            \n            loss = criterion(output, target)\n            loss.backward()\n            optimizer.step()\n            \n            \n            train_loss += loss.item()\n            \n            pred = output.max(1, keepdim=True)[1]# get the index of the max log-probability\n            num_samples += pred.shape[0]\n            correct += torch.sum(pred==target)\n            \n            \n        scheduler.step()\n        print(scheduler.get_last_lr())\n        train_loss /= num_samples\n        \n        if (100 * correct / num_samples) >= 95:\n            \n            print('Epoch: {} , Training Accuracy: {}/{} ({:.0f}%) Training Loss: {:.6f}'.format(\n                epoch+1, correct, num_samples,100. * correct / num_samples, train_loss))\n            \n            test(model,device,validloader, mode = \"Validating\")\n            test(model, device, testloader, mode = \"Test before Training on validation set\")\n            model, optimizer = trainonval(model, device, validloader, optimizer, scheduler, criterion, epochs)\n            test(model, device, testloader, mode = \"Test after training on validation set\")\n            \n            \n            \n            torch.save({\n            'model_state_dict': model.state_dict(),\n            'optimizer_state_dict': optimizer.state_dict()}, \"./model_optimizer.pt\")\n            \n            breakout = True\n            break\n            \n            \n            \n       \n        \n\n        print('Epoch: {} , Training Accuracy: {}/{} ({:.0f}%) Training Loss: {:.6f}'.format(\n                epoch+1, correct, num_samples,\n                100. * correct / num_samples, train_loss))\n        if (((epoch+1)%5) == 0) :\n            test(model,device,validloader)\n            model.train()\n            \n    if breakout:\n            print(\"breakout\")\n            return\n    \n    \n    \n    model, optimizer = trainonval(model, device, validloader, optimizer,scheduler, criterion, epochs)\n    test(model, device, testloader, mode= \"test set \")\n    \n    \n        \n    torch.save({\n            'model_state_dict': model.state_dict(),\n            'optimizer_state_dict': optimizer.state_dict()}, \"./model_optimizer.pt\")\n    \n    \n        \n","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-05-23T04:51:58.328843Z","iopub.execute_input":"2022-05-23T04:51:58.329138Z","iopub.status.idle":"2022-05-23T04:51:58.359750Z","shell.execute_reply.started":"2022-05-23T04:51:58.329104Z","shell.execute_reply":"2022-05-23T04:51:58.358636Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"n_classes = 60\n\n\nmodel = nn.Sequential(OrderedDict([\n    ('frontend', conv_3d()),\n    ('features', TimeDistributed(DenseNet3())),\n    ('backend', lstm(input_size=3240, hidden_size=1620)),\n    ('fc', nn.Sequential( nn.Dropout(p=0.5), nn.Linear(1620, 60)))\n]))\n\n\n\n\n\n# specify loss function (categorical cross-entropy)\ncriterion = nn.CrossEntropyLoss()\n# specify optimizer and learning rate\noptimizer = optim.SGD(\n    [\n        {\"params\": model.fc.parameters(), \"lr\": 1e-2},\n        {\"params\": model.features.parameters(), \"lr\": 1e-2},\n        {\"params\": model.backend.parameters(), \"lr\": 1e-2},\n        {\"params\": model.frontend.parameters(), \"lr\": 1e-2},\n  ],\n  momentum = 0.9\n)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nscheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=15, gamma=0.1, verbose = True)\nstate = torch.load(\"../input/sign-classification/model_optimizer.pt\")\nmodel.load_state_dict(state['model_state_dict'])\nmodel.half()\nmodel.cuda()\noptimizer.load_state_dict(state['optimizer_state_dict'])","metadata":{"execution":{"iopub.status.busy":"2022-05-23T04:38:20.300488Z","iopub.execute_input":"2022-05-23T04:38:20.301174Z","iopub.status.idle":"2022-05-23T04:38:25.973241Z","shell.execute_reply.started":"2022-05-23T04:38:20.301121Z","shell.execute_reply":"2022-05-23T04:38:25.972497Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ntrainloader, valloader, testloader = load_dataloaders(batch_size=4,start=start, end=end)#73 not included \n","metadata":{"execution":{"iopub.status.busy":"2022-05-23T04:38:25.974363Z","iopub.execute_input":"2022-05-23T04:38:25.974618Z","iopub.status.idle":"2022-05-23T04:41:07.351060Z","shell.execute_reply.started":"2022-05-23T04:38:25.974584Z","shell.execute_reply":"2022-05-23T04:41:07.350226Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"file p06_n019\nfile p06_n007\nfile p01_n053\nfile p04_n074\nfile p05_n077\nfile p05_n027\nfile p05_n022\nfile p01_n110\nfile p06_n036\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Number of model parameters: {}'.format(sum([p.data.nelement() for p in model.parameters()])))","metadata":{"execution":{"iopub.status.busy":"2022-05-23T04:41:07.352255Z","iopub.execute_input":"2022-05-23T04:41:07.352813Z","iopub.status.idle":"2022-05-23T04:41:07.358946Z","shell.execute_reply.started":"2022-05-23T04:41:07.352772Z","shell.execute_reply":"2022-05-23T04:41:07.358120Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Number of model parameters: 31881698\n","output_type":"stream"}]},{"cell_type":"code","source":"train(model,device,trainloader,valloader, testloader,optimizer,scheduler,criterion,50)","metadata":{"execution":{"iopub.status.busy":"2022-05-23T04:52:05.077156Z","iopub.execute_input":"2022-05-23T04:52:05.077572Z","iopub.status.idle":"2022-05-23T05:18:58.177571Z","shell.execute_reply.started":"2022-05-23T04:52:05.077537Z","shell.execute_reply":"2022-05-23T05:18:58.176333Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"Train start\nEpoch: 1 , Training Accuracy: 124/152 (82%) Training Loss: 0.346007\nEpoch: 2 , Training Accuracy: 129/152 (85%) Training Loss: 0.324437\nEpoch: 3 , Training Accuracy: 131/152 (86%) Training Loss: 0.342824\nEpoch: 4 , Training Accuracy: 114/152 (75%) Training Loss: 0.335610\nEpoch: 5 , Training Accuracy: 121/152 (80%) Training Loss: 0.323412\nValidate Accuracy: 19/31 (61%)\nEpoch: 6 , Training Accuracy: 131/152 (86%) Training Loss: 0.336942\nEpoch: 7 , Training Accuracy: 125/152 (82%) Training Loss: 0.328512\nEpoch: 8 , Training Accuracy: 132/152 (87%) Training Loss: 0.337216\nEpoch: 9 , Training Accuracy: 122/152 (80%) Training Loss: 0.352600\nEpoch: 10 , Training Accuracy: 129/152 (85%) Training Loss: 0.339609\nValidate Accuracy: 26/31 (84%)\nEpoch: 11 , Training Accuracy: 128/152 (84%) Training Loss: 0.330741\nEpoch: 12 , Training Accuracy: 121/152 (80%) Training Loss: 0.339920\nEpoch: 13 , Training Accuracy: 133/152 (88%) Training Loss: 0.342145\nEpoch: 14 , Training Accuracy: 116/152 (76%) Training Loss: 0.335277\nEpoch: 15 , Training Accuracy: 127/152 (84%) Training Loss: 0.325017\nValidate Accuracy: 21/31 (68%)\nEpoch: 16 , Training Accuracy: 123/152 (81%) Training Loss: 0.348785\nEpoch: 17 , Training Accuracy: 118/152 (78%) Training Loss: 0.334428\nEpoch: 18 , Training Accuracy: 117/152 (77%) Training Loss: 0.342404\nEpoch: 19 , Training Accuracy: 128/152 (84%) Training Loss: 0.326085\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_52/1990703009.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/tmp/ipykernel_52/441645746.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, device, train_loader, validloader, testloader, optimizer, scheduler, criterion, epochs)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhalf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_52/79319905.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m# batch size, num channels,frames,  height, width\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mBasicBlock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    586\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 587\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    581\u001b[0m             )\n\u001b[1;32m    582\u001b[0m         return F.conv3d(\n\u001b[0;32m--> 583\u001b[0;31m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdilation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    584\u001b[0m         )\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":" #test(model, device, testloader)","metadata":{"execution":{"iopub.status.busy":"2022-05-23T04:42:34.928336Z","iopub.status.idle":"2022-05-23T04:42:34.929087Z","shell.execute_reply.started":"2022-05-23T04:42:34.928844Z","shell.execute_reply":"2022-05-23T04:42:34.928870Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#from 21 15 epochs","metadata":{"execution":{"iopub.status.busy":"2022-05-23T04:42:34.930489Z","iopub.status.idle":"2022-05-23T04:42:34.931517Z","shell.execute_reply.started":"2022-05-23T04:42:34.931258Z","shell.execute_reply":"2022-05-23T04:42:34.931285Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}