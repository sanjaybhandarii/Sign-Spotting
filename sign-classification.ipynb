{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a066dac3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-10T06:46:49.789034Z",
     "iopub.status.busy": "2022-05-10T06:46:49.788509Z",
     "iopub.status.idle": "2022-05-10T06:47:11.612359Z",
     "shell.execute_reply": "2022-05-10T06:47:11.611268Z"
    },
    "papermill": {
     "duration": 21.859032,
     "end_time": "2022-05-10T06:47:11.616075",
     "exception": false,
     "start_time": "2022-05-10T06:46:49.757043",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytorchvideo\r\n",
      "  Downloading pytorchvideo-0.1.5.tar.gz (132 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.7/132.7 KB\u001b[0m \u001b[31m568.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25hCollecting fvcore\r\n",
      "  Downloading fvcore-0.1.5.post20220506.tar.gz (50 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.1/50.1 KB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25hCollecting av\r\n",
      "  Downloading av-9.2.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (28.2 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m28.2/28.2 MB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting parameterized\r\n",
      "  Downloading parameterized-0.8.1-py2.py3-none-any.whl (26 kB)\r\n",
      "Collecting iopath\r\n",
      "  Downloading iopath-0.1.9-py3-none-any.whl (27 kB)\r\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.7/site-packages (from pytorchvideo) (2.5)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from fvcore->pytorchvideo) (1.21.6)\r\n",
      "Requirement already satisfied: yacs>=0.1.6 in /opt/conda/lib/python3.7/site-packages (from fvcore->pytorchvideo) (0.1.8)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from fvcore->pytorchvideo) (6.0)\r\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from fvcore->pytorchvideo) (4.63.0)\r\n",
      "Requirement already satisfied: termcolor>=1.1 in /opt/conda/lib/python3.7/site-packages (from fvcore->pytorchvideo) (1.1.0)\r\n",
      "Requirement already satisfied: Pillow in /opt/conda/lib/python3.7/site-packages (from fvcore->pytorchvideo) (9.0.1)\r\n",
      "Requirement already satisfied: tabulate in /opt/conda/lib/python3.7/site-packages (from fvcore->pytorchvideo) (0.8.9)\r\n",
      "Requirement already satisfied: portalocker in /opt/conda/lib/python3.7/site-packages (from iopath->pytorchvideo) (2.4.0)\r\n",
      "Requirement already satisfied: decorator>=4.3.0 in /opt/conda/lib/python3.7/site-packages (from networkx->pytorchvideo) (5.1.1)\r\n",
      "Building wheels for collected packages: pytorchvideo, fvcore\r\n",
      "  Building wheel for pytorchvideo (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \bdone\r\n",
      "\u001b[?25h  Created wheel for pytorchvideo: filename=pytorchvideo-0.1.5-py3-none-any.whl size=188714 sha256=6694eac284c2027594f5b74f79200b4c81b0c5dd6fcd1958fbdf18e50fd03dac\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/e8/51/05/053b29bac2400cbbae2fb7cfc41afd280d627bca7c9363ca80\r\n",
      "  Building wheel for fvcore (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for fvcore: filename=fvcore-0.1.5.post20220506-py3-none-any.whl size=61284 sha256=d3035c9f6b62a5240f49f8554a058c215c0f75ef781bfb8755bdbdddbd17dd35\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/f5/ef/3c/708de8799f89f0871bd209866831fe3885db93fa090608fa73\r\n",
      "Successfully built pytorchvideo fvcore\r\n",
      "Installing collected packages: parameterized, av, iopath, fvcore, pytorchvideo\r\n",
      "Successfully installed av-9.2.0 fvcore-0.1.5.post20220506 iopath-0.1.9 parameterized-0.8.1 pytorchvideo-0.1.5\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install pytorchvideo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9fca8e16",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-05-10T06:47:11.732432Z",
     "iopub.status.busy": "2022-05-10T06:47:11.732026Z",
     "iopub.status.idle": "2022-05-10T06:47:14.118845Z",
     "shell.execute_reply": "2022-05-10T06:47:14.117876Z"
    },
    "papermill": {
     "duration": 2.446328,
     "end_time": "2022-05-10T06:47:14.121147",
     "exception": false,
     "start_time": "2022-05-10T06:47:11.674819",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/_functional_video.py:6: UserWarning: The _functional_video module is deprecated. Please use the functional module instead.\n",
      "  \"The _functional_video module is deprecated. Please use the functional module instead.\"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/_transforms_video.py:26: UserWarning: The _transforms_video module is deprecated. Please use the transforms module instead.\n",
      "  \"The _transforms_video module is deprecated. Please use the transforms module instead.\"\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import (\n",
    "    Dataset,\n",
    "    DataLoader,\n",
    ") \n",
    "import pickle\n",
    "\n",
    "import os\n",
    "\n",
    "import math\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchvision.transforms import Compose, Lambda, Grayscale\n",
    "from torchvision.transforms._transforms_video import CenterCropVideo, NormalizeVideo\n",
    "from pytorchvideo.data.encoded_video import EncodedVideo\n",
    "from pytorchvideo.transforms import (\n",
    "    ApplyTransformToKey,\n",
    "    UniformTemporalSubsample,\n",
    ")\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "\n",
    "class SignDataset(Dataset):\n",
    "    def __init__(self,x,y):\n",
    "        self.x = x\n",
    "        print(\"len x\" , len(self.x))\n",
    "        self.y = y\n",
    "        print(\"len y\" , len(self.y))\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "\n",
    "        return len(self.y)\n",
    "\n",
    "        # length = 0\n",
    "        # with open(self.file, 'rb') as f:\n",
    "        #     data = pickle.load(f)\n",
    "\n",
    "        # for x in data:\n",
    "        #     length += len(data[x])\n",
    "        # return length\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.x[index], self.y[index]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3899b4d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-10T06:47:14.193944Z",
     "iopub.status.busy": "2022-05-10T06:47:14.193164Z",
     "iopub.status.idle": "2022-05-10T06:47:14.209647Z",
     "shell.execute_reply": "2022-05-10T06:47:14.208725Z"
    },
    "papermill": {
     "duration": 0.056074,
     "end_time": "2022-05-10T06:47:14.212300",
     "exception": false,
     "start_time": "2022-05-10T06:47:14.156226",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "IMAGE_HEIGHT = 720\n",
    "IMAGE_WIDTH = 800\n",
    "IMAGE_CHANNEL = 1\n",
    "NUM_FRAMES = 25\n",
    "NUM_CLASSES = 60\n",
    "mean = 0\n",
    "std = 0\n",
    "\n",
    "\n",
    "\n",
    "inputs =[] #x\n",
    "classes = [] #y\n",
    "\n",
    "transform =  ApplyTransformToKey(\n",
    "    key=\"video\",\n",
    "    transform=Compose(\n",
    "        [\n",
    "            \n",
    "            Lambda(lambda x: x.permute(1,0,2,3)),#(frames(depth), channel, height, width) -> (channel, frames(depth), height, width)\n",
    "            \n",
    "            UniformTemporalSubsample(NUM_FRAMES),\n",
    "            Lambda(lambda x: x.permute(1,0,2,3)),#(frames(depth), channel, height, width)\n",
    "            \n",
    "            Lambda(lambda x: x/255.0), \n",
    "            NormalizeVideo((mean,), (std,)),\n",
    "            CenterCropVideo([720,800]),\n",
    "            Lambda(lambda x: x.permute(1,0,2,3)),#(channel, frames(depth), height, width)\n",
    "            \n",
    "            \n",
    "        ]\n",
    "        \n",
    "    ),\n",
    ")\n",
    "def get_data_info(f):\n",
    "    for line in f:\n",
    "        a = line.split(',')\n",
    "        yield a\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def load_dataloader(batch_size):\n",
    "    video = EncodedVideo.from_path(\"../input/signdataset/p01_n000.mp4\")\n",
    "        \n",
    "\n",
    "            \n",
    "\n",
    "\n",
    "    with open('../input/signdataset/p01_n000.txt') as f: \n",
    "        for x in get_data_info(f):\n",
    "            classes.append(int(x[0]))\n",
    "            start_time = x[1]\n",
    "            end_time = x[2]\n",
    "            \n",
    "            video_data = video.get_clip(start_sec=float(start_time)/1000.0, end_sec=float(end_time)/1000.0)\n",
    "\n",
    "            \n",
    "            video_data[\"video\"] = Grayscale(num_output_channels=1)((video_data[\"video\"]).permute(1,0,2,3))\n",
    "\n",
    "            #print(video_data[\"video\"].shape)\n",
    "            std, mean = torch.std_mean(video_data[\"video\"])\n",
    "            #print(std, mean)\n",
    "            video_data = transform( video_data)\n",
    "\n",
    "        # Move the inputs to the desired device\n",
    "            inputs.append(video_data[\"video\"])\n",
    "\n",
    "    signds = SignDataset(inputs, classes)\n",
    "    dataloader = DataLoader(signds, batch_size=batch_size, shuffle=True, num_workers=1)\n",
    "\n",
    "    return dataloader\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de960f01",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-10T06:47:14.283484Z",
     "iopub.status.busy": "2022-05-10T06:47:14.283203Z",
     "iopub.status.idle": "2022-05-10T06:47:14.300625Z",
     "shell.execute_reply": "2022-05-10T06:47:14.299762Z"
    },
    "papermill": {
     "duration": 0.055352,
     "end_time": "2022-05-10T06:47:14.302860",
     "exception": false,
     "start_time": "2022-05-10T06:47:14.247508",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class conv_3d(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(conv_3d, self).__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv3d(1, 64, kernel_size=5, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2)))\n",
    "        \n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv3d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2)))\n",
    "        \n",
    "\n",
    "        self._features = nn.Sequential(\n",
    "            self.conv1,\n",
    "            self.conv2\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self._features(x)\n",
    "        print(\"conv3d\", out.shape)\n",
    "        out= out.reshape(out.shape[0], out.shape[1]*out.shape[2], out.shape[3], out.shape[4])\n",
    "        print(\"reshape conv3d \",out.shape)\n",
    "        return out\n",
    "\n",
    "class conv_2d(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(conv_2d, self).__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(640, 640, kernel_size = 3, padding =1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2)))\n",
    "            \n",
    "        \n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(640, 512, kernel_size = 3, padding =1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2)))\n",
    "        \n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(512, 256, kernel_size = 3, padding =1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2)))\n",
    "        \n",
    "    \n",
    "    def forward(self,x):\n",
    "        out = self.conv2(self.conv1(x))\n",
    "        out = self.conv3(out)\n",
    "        print(out.shape)\n",
    "        out = out.view(out.shape[0],-1)\n",
    "        print(out.shape)\n",
    "        return out\n",
    "\n",
    "\n",
    "  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "94f204f6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-10T06:47:14.375362Z",
     "iopub.status.busy": "2022-05-10T06:47:14.374485Z",
     "iopub.status.idle": "2022-05-10T06:47:25.640634Z",
     "shell.execute_reply": "2022-05-10T06:47:25.639611Z"
    },
    "papermill": {
     "duration": 11.30521,
     "end_time": "2022-05-10T06:47:25.643370",
     "exception": false,
     "start_time": "2022-05-10T06:47:14.338160",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len x 11\n",
      "len y 11\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "n_classes = 60\n",
    "\n",
    "model = nn.Sequential(OrderedDict([\n",
    "    ('frontend', conv_3d()),\n",
    "    ('mid', conv_2d()),\n",
    "    ('fc', nn.Sequential( nn.Dropout(p=0.4), nn.Linear(135168, 1024),nn.Linear(1024,256), nn.Linear(256,60) ))\n",
    "]))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# specify loss function (categorical cross-entropy)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# specify optimizer and learning rate\n",
    "optimizer = optim.SGD(\n",
    "  [\n",
    "        {\"params\": model.fc.parameters(), \"lr\": 1e-3},\n",
    "        {\"params\": model.mid.parameters(), \"lr\": 1e-5},\n",
    "        {\"params\": model.frontend.parameters(), \"lr\": 1e-4},\n",
    "  ],\n",
    "  momentum = 0.9\n",
    ")\n",
    "\n",
    "\n",
    "def train(model, device, train_loader, optimizer, criterion, epoch):\n",
    "    model.cuda()\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    num_samples = 0\n",
    "    \n",
    "    for epoch in tqdm(range(epoch)):\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            \n",
    "            data = data.to(device)\n",
    "            target = torch.tensor(target).to(device)\n",
    "\n",
    "    \n",
    "    \n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "            num_samples += pred.shape[0]\n",
    "            print(num_samples)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "            print(\"correct till now:\",correct)\n",
    "        \n",
    "    train_loss /= num_samples\n",
    "    print('Epoch: {} , Training Accuracy: {}/{} ({:.0f}%) Training Loss: {:.6f}'.format(\n",
    "                epoch, correct, num_samples,\n",
    "                100. * correct / num_samples, train_loss))\n",
    "\n",
    "\n",
    "dataloader = load_dataloader(batch_size=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "58be6e5b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-10T06:47:25.718440Z",
     "iopub.status.busy": "2022-05-10T06:47:25.717503Z",
     "iopub.status.idle": "2022-05-10T06:50:17.197609Z",
     "shell.execute_reply": "2022-05-10T06:50:17.195284Z"
    },
    "papermill": {
     "duration": 171.520725,
     "end_time": "2022-05-10T06:50:17.200212",
     "exception": false,
     "start_time": "2022-05-10T06:47:25.679487",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:36: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv3d torch.Size([1, 128, 5, 179, 199])\n",
      "reshape conv3d  torch.Size([1, 640, 179, 199])\n",
      "torch.Size([1, 256, 22, 24])\n",
      "torch.Size([1, 135168])\n",
      "1\n",
      "correct till now: 0\n",
      "conv3d torch.Size([1, 128, 5, 179, 199])\n",
      "reshape conv3d  torch.Size([1, 640, 179, 199])\n",
      "torch.Size([1, 256, 22, 24])\n",
      "torch.Size([1, 135168])\n",
      "2\n",
      "correct till now: 0\n",
      "conv3d torch.Size([1, 128, 5, 179, 199])\n",
      "reshape conv3d  torch.Size([1, 640, 179, 199])\n",
      "torch.Size([1, 256, 22, 24])\n",
      "torch.Size([1, 135168])\n",
      "3\n",
      "correct till now: 0\n",
      "conv3d torch.Size([1, 128, 5, 179, 199])\n",
      "reshape conv3d  torch.Size([1, 640, 179, 199])\n",
      "torch.Size([1, 256, 22, 24])\n",
      "torch.Size([1, 135168])\n",
      "4\n",
      "correct till now: 0\n",
      "conv3d torch.Size([1, 128, 5, 179, 199])\n",
      "reshape conv3d  torch.Size([1, 640, 179, 199])\n",
      "torch.Size([1, 256, 22, 24])\n",
      "torch.Size([1, 135168])\n",
      "5\n",
      "correct till now: 0\n",
      "conv3d torch.Size([1, 128, 5, 179, 199])\n",
      "reshape conv3d  torch.Size([1, 640, 179, 199])\n",
      "torch.Size([1, 256, 22, 24])\n",
      "torch.Size([1, 135168])\n",
      "6\n",
      "correct till now: 0\n",
      "conv3d torch.Size([1, 128, 5, 179, 199])\n",
      "reshape conv3d  torch.Size([1, 640, 179, 199])\n",
      "torch.Size([1, 256, 22, 24])\n",
      "torch.Size([1, 135168])\n",
      "7\n",
      "correct till now: 0\n",
      "conv3d torch.Size([1, 128, 5, 179, 199])\n",
      "reshape conv3d  torch.Size([1, 640, 179, 199])\n",
      "torch.Size([1, 256, 22, 24])\n",
      "torch.Size([1, 135168])\n",
      "8\n",
      "correct till now: 0\n",
      "conv3d torch.Size([1, 128, 5, 179, 199])\n",
      "reshape conv3d  torch.Size([1, 640, 179, 199])\n",
      "torch.Size([1, 256, 22, 24])\n",
      "torch.Size([1, 135168])\n",
      "9\n",
      "correct till now: 0\n",
      "conv3d torch.Size([1, 128, 5, 179, 199])\n",
      "reshape conv3d  torch.Size([1, 640, 179, 199])\n",
      "torch.Size([1, 256, 22, 24])\n",
      "torch.Size([1, 135168])\n",
      "10\n",
      "correct till now: 0\n",
      "conv3d torch.Size([1, 128, 5, 179, 199])\n",
      "reshape conv3d  torch.Size([1, 640, 179, 199])\n",
      "torch.Size([1, 256, 22, 24])\n",
      "torch.Size([1, 135168])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:22<03:23, 22.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "correct till now: 0\n",
      "conv3d torch.Size([1, 128, 5, 179, 199])\n",
      "reshape conv3d  torch.Size([1, 640, 179, 199])\n",
      "torch.Size([1, 256, 22, 24])\n",
      "torch.Size([1, 135168])\n",
      "12\n",
      "correct till now: 0\n",
      "conv3d torch.Size([1, 128, 5, 179, 199])\n",
      "reshape conv3d  torch.Size([1, 640, 179, 199])\n",
      "torch.Size([1, 256, 22, 24])\n",
      "torch.Size([1, 135168])\n",
      "13\n",
      "correct till now: 0\n",
      "conv3d torch.Size([1, 128, 5, 179, 199])\n",
      "reshape conv3d  torch.Size([1, 640, 179, 199])\n",
      "torch.Size([1, 256, 22, 24])\n",
      "torch.Size([1, 135168])\n",
      "14\n",
      "correct till now: 0\n",
      "conv3d torch.Size([1, 128, 5, 179, 199])\n",
      "reshape conv3d  torch.Size([1, 640, 179, 199])\n",
      "torch.Size([1, 256, 22, 24])\n",
      "torch.Size([1, 135168])\n",
      "15\n",
      "correct till now: 0\n",
      "conv3d torch.Size([1, 128, 5, 179, 199])\n",
      "reshape conv3d  torch.Size([1, 640, 179, 199])\n",
      "torch.Size([1, 256, 22, 24])\n",
      "torch.Size([1, 135168])\n",
      "16\n",
      "correct till now: 0\n",
      "conv3d torch.Size([1, 128, 5, 179, 199])\n",
      "reshape conv3d  torch.Size([1, 640, 179, 199])\n",
      "torch.Size([1, 256, 22, 24])\n",
      "torch.Size([1, 135168])\n",
      "17\n",
      "correct till now: 0\n",
      "conv3d torch.Size([1, 128, 5, 179, 199])\n",
      "reshape conv3d  torch.Size([1, 640, 179, 199])\n",
      "torch.Size([1, 256, 22, 24])\n",
      "torch.Size([1, 135168])\n",
      "18\n",
      "correct till now: 0\n",
      "conv3d torch.Size([1, 128, 5, 179, 199])\n",
      "reshape conv3d  torch.Size([1, 640, 179, 199])\n",
      "torch.Size([1, 256, 22, 24])\n",
      "torch.Size([1, 135168])\n",
      "19\n",
      "correct till now: 0\n",
      "conv3d torch.Size([1, 128, 5, 179, 199])\n",
      "reshape conv3d  torch.Size([1, 640, 179, 199])\n",
      "torch.Size([1, 256, 22, 24])\n",
      "torch.Size([1, 135168])\n",
      "20\n",
      "correct till now: 0\n",
      "conv3d torch.Size([1, 128, 5, 179, 199])\n",
      "reshape conv3d  torch.Size([1, 640, 179, 199])\n",
      "torch.Size([1, 256, 22, 24])\n",
      "torch.Size([1, 135168])\n",
      "21\n",
      "correct till now: 0\n",
      "conv3d torch.Size([1, 128, 5, 179, 199])\n",
      "reshape conv3d  torch.Size([1, 640, 179, 199])\n",
      "torch.Size([1, 256, 22, 24])\n",
      "torch.Size([1, 135168])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [00:38<02:30, 18.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n",
      "correct till now: 0\n",
      "conv3d torch.Size([1, 128, 5, 179, 199])\n",
      "reshape conv3d  torch.Size([1, 640, 179, 199])\n",
      "torch.Size([1, 256, 22, 24])\n",
      "torch.Size([1, 135168])\n",
      "23\n",
      "correct till now: 0\n",
      "conv3d torch.Size([1, 128, 5, 179, 199])\n",
      "reshape conv3d  torch.Size([1, 640, 179, 199])\n",
      "torch.Size([1, 256, 22, 24])\n",
      "torch.Size([1, 135168])\n",
      "24\n",
      "correct till now: 0\n",
      "conv3d torch.Size([1, 128, 5, 179, 199])\n",
      "reshape conv3d  torch.Size([1, 640, 179, 199])\n",
      "torch.Size([1, 256, 22, 24])\n",
      "torch.Size([1, 135168])\n",
      "25\n",
      "correct till now: 0\n",
      "conv3d torch.Size([1, 128, 5, 179, 199])\n",
      "reshape conv3d  torch.Size([1, 640, 179, 199])\n",
      "torch.Size([1, 256, 22, 24])\n",
      "torch.Size([1, 135168])\n",
      "26\n",
      "correct till now: 0\n",
      "conv3d torch.Size([1, 128, 5, 179, 199])\n",
      "reshape conv3d  torch.Size([1, 640, 179, 199])\n",
      "torch.Size([1, 256, 22, 24])\n",
      "torch.Size([1, 135168])\n",
      "27\n",
      "correct till now: 0\n",
      "conv3d torch.Size([1, 128, 5, 179, 199])\n",
      "reshape conv3d  torch.Size([1, 640, 179, 199])\n",
      "torch.Size([1, 256, 22, 24])\n",
      "torch.Size([1, 135168])\n",
      "28\n",
      "correct till now: 0\n",
      "conv3d torch.Size([1, 128, 5, 179, 199])\n",
      "reshape conv3d  torch.Size([1, 640, 179, 199])\n",
      "torch.Size([1, 256, 22, 24])\n",
      "torch.Size([1, 135168])\n",
      "29\n",
      "correct till now: 0\n",
      "conv3d torch.Size([1, 128, 5, 179, 199])\n",
      "reshape conv3d  torch.Size([1, 640, 179, 199])\n",
      "torch.Size([1, 256, 22, 24])\n",
      "torch.Size([1, 135168])\n",
      "30\n",
      "correct till now: 0\n",
      "conv3d torch.Size([1, 128, 5, 179, 199])\n",
      "reshape conv3d  torch.Size([1, 640, 179, 199])\n",
      "torch.Size([1, 256, 22, 24])\n",
      "torch.Size([1, 135168])\n",
      "31\n",
      "correct till now: 0\n",
      "conv3d torch.Size([1, 128, 5, 179, 199])\n",
      "reshape conv3d  torch.Size([1, 640, 179, 199])\n",
      "torch.Size([1, 256, 22, 24])\n",
      "torch.Size([1, 135168])\n",
      "32\n",
      "correct till now: 0\n",
      "conv3d torch.Size([1, 128, 5, 179, 199])\n",
      "reshape conv3d  torch.Size([1, 640, 179, 199])\n",
      "torch.Size([1, 256, 22, 24])\n",
      "torch.Size([1, 135168])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [00:55<02:03, 17.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33\n",
      "correct till now: 0\n",
      "conv3d torch.Size([1, 128, 5, 179, 199])\n",
      "reshape conv3d  torch.Size([1, 640, 179, 199])\n",
      "torch.Size([1, 256, 22, 24])\n",
      "torch.Size([1, 135168])\n",
      "34\n",
      "correct till now: 0\n",
      "conv3d torch.Size([1, 128, 5, 179, 199])\n",
      "reshape conv3d  torch.Size([1, 640, 179, 199])\n",
      "torch.Size([1, 256, 22, 24])\n",
      "torch.Size([1, 135168])\n",
      "35\n",
      "correct till now: 0\n",
      "conv3d torch.Size([1, 128, 5, 179, 199])\n",
      "reshape conv3d  torch.Size([1, 640, 179, 199])\n",
      "torch.Size([1, 256, 22, 24])\n",
      "torch.Size([1, 135168])\n",
      "36\n",
      "correct till now: 0\n",
      "conv3d torch.Size([1, 128, 5, 179, 199])\n",
      "reshape conv3d  torch.Size([1, 640, 179, 199])\n",
      "torch.Size([1, 256, 22, 24])\n",
      "torch.Size([1, 135168])\n",
      "37\n",
      "correct till now: 0\n",
      "conv3d torch.Size([1, 128, 5, 179, 199])\n",
      "reshape conv3d  torch.Size([1, 640, 179, 199])\n",
      "torch.Size([1, 256, 22, 24])\n",
      "torch.Size([1, 135168])\n",
      "38\n",
      "correct till now: 0\n",
      "conv3d torch.Size([1, 128, 5, 179, 199])\n",
      "reshape conv3d  torch.Size([1, 640, 179, 199])\n",
      "torch.Size([1, 256, 22, 24])\n",
      "torch.Size([1, 135168])\n",
      "39\n",
      "correct till now: 0\n",
      "conv3d torch.Size([1, 128, 5, 179, 199])\n",
      "reshape conv3d  torch.Size([1, 640, 179, 199])\n",
      "torch.Size([1, 256, 22, 24])\n",
      "torch.Size([1, 135168])\n",
      "40\n",
      "correct till now: 0\n",
      "conv3d torch.Size([1, 128, 5, 179, 199])\n",
      "reshape conv3d  torch.Size([1, 640, 179, 199])\n",
      "torch.Size([1, 256, 22, 24])\n",
      "torch.Size([1, 135168])\n",
      "41\n",
      "correct till now: 0\n",
      "conv3d torch.Size([1, 128, 5, 179, 199])\n",
      "reshape conv3d  torch.Size([1, 640, 179, 199])\n",
      "torch.Size([1, 256, 22, 24])\n",
      "torch.Size([1, 135168])\n",
      "42\n",
      "correct till now: 0\n",
      "conv3d torch.Size([1, 128, 5, 179, 199])\n",
      "reshape conv3d  torch.Size([1, 640, 179, 199])\n",
      "torch.Size([1, 256, 22, 24])\n",
      "torch.Size([1, 135168])\n",
      "43\n",
      "correct till now: 0\n",
      "conv3d torch.Size([1, 128, 5, 179, 199])\n",
      "reshape conv3d  torch.Size([1, 640, 179, 199])\n",
      "torch.Size([1, 256, 22, 24])\n",
      "torch.Size([1, 135168])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [01:11<01:42, 17.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44\n",
      "correct till now: 0\n",
      "conv3d torch.Size([1, 128, 5, 179, 199])\n",
      "reshape conv3d  torch.Size([1, 640, 179, 199])\n",
      "torch.Size([1, 256, 22, 24])\n",
      "torch.Size([1, 135168])\n",
      "45\n",
      "correct till now: 0\n",
      "conv3d torch.Size([1, 128, 5, 179, 199])\n",
      "reshape conv3d  torch.Size([1, 640, 179, 199])\n",
      "torch.Size([1, 256, 22, 24])\n",
      "torch.Size([1, 135168])\n",
      "46\n",
      "correct till now: 0\n",
      "conv3d torch.Size([1, 128, 5, 179, 199])\n",
      "reshape conv3d  torch.Size([1, 640, 179, 199])\n",
      "torch.Size([1, 256, 22, 24])\n",
      "torch.Size([1, 135168])\n",
      "47\n",
      "correct till now: 0\n",
      "conv3d torch.Size([1, 128, 5, 179, 199])\n",
      "reshape conv3d  torch.Size([1, 640, 179, 199])\n",
      "torch.Size([1, 256, 22, 24])\n",
      "torch.Size([1, 135168])\n",
      "48\n",
      "correct till now: 0\n",
      "conv3d torch.Size([1, 128, 5, 179, 199])\n",
      "reshape conv3d  torch.Size([1, 640, 179, 199])\n",
      "torch.Size([1, 256, 22, 24])\n",
      "torch.Size([1, 135168])\n",
      "49\n",
      "correct till now: 0\n",
      "conv3d torch.Size([1, 128, 5, 179, 199])\n",
      "reshape conv3d  torch.Size([1, 640, 179, 199])\n",
      "torch.Size([1, 256, 22, 24])\n",
      "torch.Size([1, 135168])\n",
      "50\n",
      "correct till now: 0\n",
      "conv3d torch.Size([1, 128, 5, 179, 199])\n",
      "reshape conv3d  torch.Size([1, 640, 179, 199])\n",
      "torch.Size([1, 256, 22, 24])\n",
      "torch.Size([1, 135168])\n",
      "51\n",
      "correct till now: 0\n",
      "conv3d torch.Size([1, 128, 5, 179, 199])\n",
      "reshape conv3d  torch.Size([1, 640, 179, 199])\n",
      "torch.Size([1, 256, 22, 24])\n",
      "torch.Size([1, 135168])\n",
      "52\n",
      "correct till now: 0\n",
      "conv3d torch.Size([1, 128, 5, 179, 199])\n",
      "reshape conv3d  torch.Size([1, 640, 179, 199])\n",
      "torch.Size([1, 256, 22, 24])\n",
      "torch.Size([1, 135168])\n",
      "53\n",
      "correct till now: 0\n",
      "conv3d torch.Size([1, 128, 5, 179, 199])\n",
      "reshape conv3d  torch.Size([1, 640, 179, 199])\n",
      "torch.Size([1, 256, 22, 24])\n",
      "torch.Size([1, 135168])\n",
      "54\n",
      "correct till now: 0\n",
      "conv3d torch.Size([1, 128, 5, 179, 199])\n",
      "reshape conv3d  torch.Size([1, 640, 179, 199])\n",
      "torch.Size([1, 256, 22, 24])\n",
      "torch.Size([1, 135168])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [01:27<01:23, 16.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55\n",
      "correct till now: 0\n",
      "conv3d torch.Size([1, 128, 5, 179, 199])\n",
      "reshape conv3d  torch.Size([1, 640, 179, 199])\n",
      "torch.Size([1, 256, 22, 24])\n",
      "torch.Size([1, 135168])\n",
      "56\n",
      "correct till now: 0\n",
      "conv3d torch.Size([1, 128, 5, 179, 199])\n",
      "reshape conv3d  torch.Size([1, 640, 179, 199])\n",
      "torch.Size([1, 256, 22, 24])\n",
      "torch.Size([1, 135168])\n",
      "57\n",
      "correct till now: 0\n",
      "conv3d torch.Size([1, 128, 5, 179, 199])\n",
      "reshape conv3d  torch.Size([1, 640, 179, 199])\n",
      "torch.Size([1, 256, 22, 24])\n",
      "torch.Size([1, 135168])\n",
      "58\n",
      "correct till now: 0\n",
      "conv3d torch.Size([1, 128, 5, 179, 199])\n",
      "reshape conv3d  torch.Size([1, 640, 179, 199])\n",
      "torch.Size([1, 256, 22, 24])\n",
      "torch.Size([1, 135168])\n",
      "59\n",
      "correct till now: 0\n",
      "conv3d torch.Size([1, 128, 5, 179, 199])\n",
      "reshape conv3d  torch.Size([1, 640, 179, 199])\n",
      "torch.Size([1, 256, 22, 24])\n",
      "torch.Size([1, 135168])\n",
      "60\n",
      "correct till now: 0\n",
      "conv3d torch.Size([1, 128, 5, 179, 199])\n",
      "reshape conv3d  torch.Size([1, 640, 179, 199])\n",
      "torch.Size([1, 256, 22, 24])\n",
      "torch.Size([1, 135168])\n",
      "61\n",
      "correct till now: 0\n",
      "conv3d torch.Size([1, 128, 5, 179, 199])\n",
      "reshape conv3d  torch.Size([1, 640, 179, 199])\n",
      "torch.Size([1, 256, 22, 24])\n",
      "torch.Size([1, 135168])\n",
      "62\n",
      "correct till now: 0\n",
      "conv3d torch.Size([1, 128, 5, 179, 199])\n",
      "reshape conv3d  torch.Size([1, 640, 179, 199])\n",
      "torch.Size([1, 256, 22, 24])\n",
      "torch.Size([1, 135168])\n",
      "63\n",
      "correct till now: 0\n",
      "conv3d torch.Size([1, 128, 5, 179, 199])\n",
      "reshape conv3d  torch.Size([1, 640, 179, 199])\n",
      "torch.Size([1, 256, 22, 24])\n",
      "torch.Size([1, 135168])\n",
      "64\n",
      "correct till now: 0\n",
      "conv3d torch.Size([1, 128, 5, 179, 199])\n",
      "reshape conv3d  torch.Size([1, 640, 179, 199])\n",
      "torch.Size([1, 256, 22, 24])\n",
      "torch.Size([1, 135168])\n",
      "65\n",
      "correct till now: 0\n",
      "conv3d torch.Size([1, 128, 5, 179, 199])\n",
      "reshape conv3d  torch.Size([1, 640, 179, 199])\n",
      "torch.Size([1, 256, 22, 24])\n",
      "torch.Size([1, 135168])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [01:43<01:06, 16.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66\n",
      "correct till now: 0\n",
      "conv3d torch.Size([1, 128, 5, 179, 199])\n",
      "reshape conv3d  torch.Size([1, 640, 179, 199])\n",
      "torch.Size([1, 256, 22, 24])\n",
      "torch.Size([1, 135168])\n",
      "67\n",
      "correct till now: 0\n",
      "conv3d torch.Size([1, 128, 5, 179, 199])\n",
      "reshape conv3d  torch.Size([1, 640, 179, 199])\n",
      "torch.Size([1, 256, 22, 24])\n",
      "torch.Size([1, 135168])\n",
      "68\n",
      "correct till now: 0\n",
      "conv3d torch.Size([1, 128, 5, 179, 199])\n",
      "reshape conv3d  torch.Size([1, 640, 179, 199])\n",
      "torch.Size([1, 256, 22, 24])\n",
      "torch.Size([1, 135168])\n",
      "69\n",
      "correct till now: 0\n",
      "conv3d torch.Size([1, 128, 5, 179, 199])\n",
      "reshape conv3d  torch.Size([1, 640, 179, 199])\n",
      "torch.Size([1, 256, 22, 24])\n",
      "torch.Size([1, 135168])\n",
      "70\n",
      "correct till now: 0\n",
      "conv3d torch.Size([1, 128, 5, 179, 199])\n",
      "reshape conv3d  torch.Size([1, 640, 179, 199])\n",
      "torch.Size([1, 256, 22, 24])\n",
      "torch.Size([1, 135168])\n",
      "71\n",
      "correct till now: 0\n",
      "conv3d torch.Size([1, 128, 5, 179, 199])\n",
      "reshape conv3d  torch.Size([1, 640, 179, 199])\n",
      "torch.Size([1, 256, 22, 24])\n",
      "torch.Size([1, 135168])\n",
      "72\n",
      "correct till now: 0\n",
      "conv3d torch.Size([1, 128, 5, 179, 199])\n",
      "reshape conv3d  torch.Size([1, 640, 179, 199])\n",
      "torch.Size([1, 256, 22, 24])\n",
      "torch.Size([1, 135168])\n",
      "73\n",
      "correct till now: 0\n",
      "conv3d torch.Size([1, 128, 5, 179, 199])\n",
      "reshape conv3d  torch.Size([1, 640, 179, 199])\n",
      "torch.Size([1, 256, 22, 24])\n",
      "torch.Size([1, 135168])\n",
      "74\n",
      "correct till now: 0\n",
      "conv3d torch.Size([1, 128, 5, 179, 199])\n",
      "reshape conv3d  torch.Size([1, 640, 179, 199])\n",
      "torch.Size([1, 256, 22, 24])\n",
      "torch.Size([1, 135168])\n",
      "75\n",
      "correct till now: 0\n",
      "conv3d torch.Size([1, 128, 5, 179, 199])\n",
      "reshape conv3d  torch.Size([1, 640, 179, 199])\n",
      "torch.Size([1, 256, 22, 24])\n",
      "torch.Size([1, 135168])\n",
      "76\n",
      "correct till now: 0\n",
      "conv3d torch.Size([1, 128, 5, 179, 199])\n",
      "reshape conv3d  torch.Size([1, 640, 179, 199])\n",
      "torch.Size([1, 256, 22, 24])\n",
      "torch.Size([1, 135168])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [01:59<00:49, 16.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77\n",
      "correct till now: 0\n",
      "conv3d torch.Size([1, 128, 5, 179, 199])\n",
      "reshape conv3d  torch.Size([1, 640, 179, 199])\n",
      "torch.Size([1, 256, 22, 24])\n",
      "torch.Size([1, 135168])\n",
      "78\n",
      "correct till now: 0\n",
      "conv3d torch.Size([1, 128, 5, 179, 199])\n",
      "reshape conv3d  torch.Size([1, 640, 179, 199])\n",
      "torch.Size([1, 256, 22, 24])\n",
      "torch.Size([1, 135168])\n",
      "79\n",
      "correct till now: 0\n",
      "conv3d torch.Size([1, 128, 5, 179, 199])\n",
      "reshape conv3d  torch.Size([1, 640, 179, 199])\n",
      "torch.Size([1, 256, 22, 24])\n",
      "torch.Size([1, 135168])\n",
      "80\n",
      "correct till now: 0\n",
      "conv3d torch.Size([1, 128, 5, 179, 199])\n",
      "reshape conv3d  torch.Size([1, 640, 179, 199])\n",
      "torch.Size([1, 256, 22, 24])\n",
      "torch.Size([1, 135168])\n",
      "81\n",
      "correct till now: 0\n",
      "conv3d torch.Size([1, 128, 5, 179, 199])\n",
      "reshape conv3d  torch.Size([1, 640, 179, 199])\n",
      "torch.Size([1, 256, 22, 24])\n",
      "torch.Size([1, 135168])\n",
      "82\n",
      "correct till now: 0\n",
      "conv3d torch.Size([1, 128, 5, 179, 199])\n",
      "reshape conv3d  torch.Size([1, 640, 179, 199])\n",
      "torch.Size([1, 256, 22, 24])\n",
      "torch.Size([1, 135168])\n",
      "83\n",
      "correct till now: 0\n",
      "conv3d torch.Size([1, 128, 5, 179, 199])\n",
      "reshape conv3d  torch.Size([1, 640, 179, 199])\n",
      "torch.Size([1, 256, 22, 24])\n",
      "torch.Size([1, 135168])\n",
      "84\n",
      "correct till now: 0\n",
      "conv3d torch.Size([1, 128, 5, 179, 199])\n",
      "reshape conv3d  torch.Size([1, 640, 179, 199])\n",
      "torch.Size([1, 256, 22, 24])\n",
      "torch.Size([1, 135168])\n",
      "85\n",
      "correct till now: 0\n",
      "conv3d torch.Size([1, 128, 5, 179, 199])\n",
      "reshape conv3d  torch.Size([1, 640, 179, 199])\n",
      "torch.Size([1, 256, 22, 24])\n",
      "torch.Size([1, 135168])\n",
      "86\n",
      "correct till now: 0\n",
      "conv3d torch.Size([1, 128, 5, 179, 199])\n",
      "reshape conv3d  torch.Size([1, 640, 179, 199])\n",
      "torch.Size([1, 256, 22, 24])\n",
      "torch.Size([1, 135168])\n",
      "87\n",
      "correct till now: 0\n",
      "conv3d torch.Size([1, 128, 5, 179, 199])\n",
      "reshape conv3d  torch.Size([1, 640, 179, 199])\n",
      "torch.Size([1, 256, 22, 24])\n",
      "torch.Size([1, 135168])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [02:15<00:32, 16.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88\n",
      "correct till now: 0\n",
      "conv3d torch.Size([1, 128, 5, 179, 199])\n",
      "reshape conv3d  torch.Size([1, 640, 179, 199])\n",
      "torch.Size([1, 256, 22, 24])\n",
      "torch.Size([1, 135168])\n",
      "89\n",
      "correct till now: 0\n",
      "conv3d torch.Size([1, 128, 5, 179, 199])\n",
      "reshape conv3d  torch.Size([1, 640, 179, 199])\n",
      "torch.Size([1, 256, 22, 24])\n",
      "torch.Size([1, 135168])\n",
      "90\n",
      "correct till now: 0\n",
      "conv3d torch.Size([1, 128, 5, 179, 199])\n",
      "reshape conv3d  torch.Size([1, 640, 179, 199])\n",
      "torch.Size([1, 256, 22, 24])\n",
      "torch.Size([1, 135168])\n",
      "91\n",
      "correct till now: 0\n",
      "conv3d torch.Size([1, 128, 5, 179, 199])\n",
      "reshape conv3d  torch.Size([1, 640, 179, 199])\n",
      "torch.Size([1, 256, 22, 24])\n",
      "torch.Size([1, 135168])\n",
      "92\n",
      "correct till now: 0\n",
      "conv3d torch.Size([1, 128, 5, 179, 199])\n",
      "reshape conv3d  torch.Size([1, 640, 179, 199])\n",
      "torch.Size([1, 256, 22, 24])\n",
      "torch.Size([1, 135168])\n",
      "93\n",
      "correct till now: 0\n",
      "conv3d torch.Size([1, 128, 5, 179, 199])\n",
      "reshape conv3d  torch.Size([1, 640, 179, 199])\n",
      "torch.Size([1, 256, 22, 24])\n",
      "torch.Size([1, 135168])\n",
      "94\n",
      "correct till now: 0\n",
      "conv3d torch.Size([1, 128, 5, 179, 199])\n",
      "reshape conv3d  torch.Size([1, 640, 179, 199])\n",
      "torch.Size([1, 256, 22, 24])\n",
      "torch.Size([1, 135168])\n",
      "95\n",
      "correct till now: 0\n",
      "conv3d torch.Size([1, 128, 5, 179, 199])\n",
      "reshape conv3d  torch.Size([1, 640, 179, 199])\n",
      "torch.Size([1, 256, 22, 24])\n",
      "torch.Size([1, 135168])\n",
      "96\n",
      "correct till now: 0\n",
      "conv3d torch.Size([1, 128, 5, 179, 199])\n",
      "reshape conv3d  torch.Size([1, 640, 179, 199])\n",
      "torch.Size([1, 256, 22, 24])\n",
      "torch.Size([1, 135168])\n",
      "97\n",
      "correct till now: 0\n",
      "conv3d torch.Size([1, 128, 5, 179, 199])\n",
      "reshape conv3d  torch.Size([1, 640, 179, 199])\n",
      "torch.Size([1, 256, 22, 24])\n",
      "torch.Size([1, 135168])\n",
      "98\n",
      "correct till now: 0\n",
      "conv3d torch.Size([1, 128, 5, 179, 199])\n",
      "reshape conv3d  torch.Size([1, 640, 179, 199])\n",
      "torch.Size([1, 256, 22, 24])\n",
      "torch.Size([1, 135168])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [02:32<00:16, 16.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99\n",
      "correct till now: 0\n",
      "conv3d torch.Size([1, 128, 5, 179, 199])\n",
      "reshape conv3d  torch.Size([1, 640, 179, 199])\n",
      "torch.Size([1, 256, 22, 24])\n",
      "torch.Size([1, 135168])\n",
      "100\n",
      "correct till now: 0\n",
      "conv3d torch.Size([1, 128, 5, 179, 199])\n",
      "reshape conv3d  torch.Size([1, 640, 179, 199])\n",
      "torch.Size([1, 256, 22, 24])\n",
      "torch.Size([1, 135168])\n",
      "101\n",
      "correct till now: 0\n",
      "conv3d torch.Size([1, 128, 5, 179, 199])\n",
      "reshape conv3d  torch.Size([1, 640, 179, 199])\n",
      "torch.Size([1, 256, 22, 24])\n",
      "torch.Size([1, 135168])\n",
      "102\n",
      "correct till now: 0\n",
      "conv3d torch.Size([1, 128, 5, 179, 199])\n",
      "reshape conv3d  torch.Size([1, 640, 179, 199])\n",
      "torch.Size([1, 256, 22, 24])\n",
      "torch.Size([1, 135168])\n",
      "103\n",
      "correct till now: 0\n",
      "conv3d torch.Size([1, 128, 5, 179, 199])\n",
      "reshape conv3d  torch.Size([1, 640, 179, 199])\n",
      "torch.Size([1, 256, 22, 24])\n",
      "torch.Size([1, 135168])\n",
      "104\n",
      "correct till now: 0\n",
      "conv3d torch.Size([1, 128, 5, 179, 199])\n",
      "reshape conv3d  torch.Size([1, 640, 179, 199])\n",
      "torch.Size([1, 256, 22, 24])\n",
      "torch.Size([1, 135168])\n",
      "105\n",
      "correct till now: 0\n",
      "conv3d torch.Size([1, 128, 5, 179, 199])\n",
      "reshape conv3d  torch.Size([1, 640, 179, 199])\n",
      "torch.Size([1, 256, 22, 24])\n",
      "torch.Size([1, 135168])\n",
      "106\n",
      "correct till now: 0\n",
      "conv3d torch.Size([1, 128, 5, 179, 199])\n",
      "reshape conv3d  torch.Size([1, 640, 179, 199])\n",
      "torch.Size([1, 256, 22, 24])\n",
      "torch.Size([1, 135168])\n",
      "107\n",
      "correct till now: 0\n",
      "conv3d torch.Size([1, 128, 5, 179, 199])\n",
      "reshape conv3d  torch.Size([1, 640, 179, 199])\n",
      "torch.Size([1, 256, 22, 24])\n",
      "torch.Size([1, 135168])\n",
      "108\n",
      "correct till now: 0\n",
      "conv3d torch.Size([1, 128, 5, 179, 199])\n",
      "reshape conv3d  torch.Size([1, 640, 179, 199])\n",
      "torch.Size([1, 256, 22, 24])\n",
      "torch.Size([1, 135168])\n",
      "109\n",
      "correct till now: 0\n",
      "conv3d torch.Size([1, 128, 5, 179, 199])\n",
      "reshape conv3d  torch.Size([1, 640, 179, 199])\n",
      "torch.Size([1, 256, 22, 24])\n",
      "torch.Size([1, 135168])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [02:48<00:00, 16.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110\n",
      "correct till now: 0\n",
      "Epoch: 9 , Training Accuracy: 0/110 (0%) Training Loss: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "train(model,device,dataloader,optimizer,criterion,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3d3985",
   "metadata": {
    "papermill": {
     "duration": 0.131013,
     "end_time": "2022-05-10T06:50:17.460459",
     "exception": false,
     "start_time": "2022-05-10T06:50:17.329446",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ea405d",
   "metadata": {
    "papermill": {
     "duration": 0.128712,
     "end_time": "2022-05-10T06:50:17.717959",
     "exception": false,
     "start_time": "2022-05-10T06:50:17.589247",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b15465",
   "metadata": {
    "papermill": {
     "duration": 0.130527,
     "end_time": "2022-05-10T06:50:18.008954",
     "exception": false,
     "start_time": "2022-05-10T06:50:17.878427",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 219.701649,
   "end_time": "2022-05-10T06:50:19.867709",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-05-10T06:46:40.166060",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
