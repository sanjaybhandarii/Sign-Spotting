{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81540171",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-23T06:04:57.983438Z",
     "iopub.status.busy": "2022-05-23T06:04:57.982804Z",
     "iopub.status.idle": "2022-05-23T06:05:17.969359Z",
     "shell.execute_reply": "2022-05-23T06:05:17.968285Z"
    },
    "papermill": {
     "duration": 20.006211,
     "end_time": "2022-05-23T06:05:17.971713",
     "exception": false,
     "start_time": "2022-05-23T06:04:57.965502",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytorchvideo\r\n",
      "  Downloading pytorchvideo-0.1.5.tar.gz (132 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.7/132.7 KB\u001b[0m \u001b[31m330.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25hCollecting fvcore\r\n",
      "  Downloading fvcore-0.1.5.post20220512.tar.gz (50 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.1/50.1 KB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25hCollecting av\r\n",
      "  Downloading av-9.2.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (28.2 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m28.2/28.2 MB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting parameterized\r\n",
      "  Downloading parameterized-0.8.1-py2.py3-none-any.whl (26 kB)\r\n",
      "Collecting iopath\r\n",
      "  Downloading iopath-0.1.9-py3-none-any.whl (27 kB)\r\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.7/site-packages (from pytorchvideo) (2.5)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from fvcore->pytorchvideo) (1.21.6)\r\n",
      "Requirement already satisfied: yacs>=0.1.6 in /opt/conda/lib/python3.7/site-packages (from fvcore->pytorchvideo) (0.1.8)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from fvcore->pytorchvideo) (6.0)\r\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from fvcore->pytorchvideo) (4.63.0)\r\n",
      "Requirement already satisfied: termcolor>=1.1 in /opt/conda/lib/python3.7/site-packages (from fvcore->pytorchvideo) (1.1.0)\r\n",
      "Requirement already satisfied: Pillow in /opt/conda/lib/python3.7/site-packages (from fvcore->pytorchvideo) (9.0.1)\r\n",
      "Requirement already satisfied: tabulate in /opt/conda/lib/python3.7/site-packages (from fvcore->pytorchvideo) (0.8.9)\r\n",
      "Requirement already satisfied: portalocker in /opt/conda/lib/python3.7/site-packages (from iopath->pytorchvideo) (2.4.0)\r\n",
      "Requirement already satisfied: decorator>=4.3.0 in /opt/conda/lib/python3.7/site-packages (from networkx->pytorchvideo) (5.1.1)\r\n",
      "Building wheels for collected packages: pytorchvideo, fvcore\r\n",
      "  Building wheel for pytorchvideo (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for pytorchvideo: filename=pytorchvideo-0.1.5-py3-none-any.whl size=188714 sha256=c7ff32adc1338c08f1b62ad127975625d64f0d3c9e283e50cbde7fb9ac797a73\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/e8/51/05/053b29bac2400cbbae2fb7cfc41afd280d627bca7c9363ca80\r\n",
      "  Building wheel for fvcore (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25h  Created wheel for fvcore: filename=fvcore-0.1.5.post20220512-py3-none-any.whl size=61288 sha256=56a041e796c57732921d6d96f4d6db3640d67c96b1746304b195bdd727a9a1e6\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/68/20/f9/a11a0dd63f4c13678b2a5ec488e48078756505c7777b75b29e\r\n",
      "Successfully built pytorchvideo fvcore\r\n",
      "Installing collected packages: parameterized, av, iopath, fvcore, pytorchvideo\r\n",
      "Successfully installed av-9.2.0 fvcore-0.1.5.post20220512 iopath-0.1.9 parameterized-0.8.1 pytorchvideo-0.1.5\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install pytorchvideo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "465156be",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-23T06:05:18.051325Z",
     "iopub.status.busy": "2022-05-23T06:05:18.049950Z",
     "iopub.status.idle": "2022-05-23T06:05:18.054972Z",
     "shell.execute_reply": "2022-05-23T06:05:18.054333Z"
    },
    "papermill": {
     "duration": 0.04479,
     "end_time": "2022-05-23T06:05:18.056539",
     "exception": false,
     "start_time": "2022-05-23T06:05:18.011749",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "start= 1\n",
    "end = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8dfe7eac",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-05-23T06:05:18.130972Z",
     "iopub.status.busy": "2022-05-23T06:05:18.130346Z",
     "iopub.status.idle": "2022-05-23T06:05:20.100891Z",
     "shell.execute_reply": "2022-05-23T06:05:20.100176Z"
    },
    "papermill": {
     "duration": 2.009828,
     "end_time": "2022-05-23T06:05:20.102892",
     "exception": false,
     "start_time": "2022-05-23T06:05:18.093064",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import (\n",
    "    Dataset,\n",
    "    DataLoader,\n",
    ") \n",
    "import pickle\n",
    "\n",
    "\n",
    "import os\n",
    "\n",
    "import math\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchvision.transforms import Compose, Lambda, Grayscale,Normalize, CenterCrop,Resize\n",
    "#from torchvision.transforms._transforms_video import CenterCropVideo\n",
    "from pytorchvideo.data.encoded_video import EncodedVideo\n",
    "from pytorchvideo.transforms import (\n",
    "    ApplyTransformToKey,\n",
    "    UniformTemporalSubsample,\n",
    ")\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class SignDataset(Dataset):\n",
    "    def __init__(self,x,y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "\n",
    "        return len(self.y)\n",
    "\n",
    "        # length = 0\n",
    "        # with open(self.file, 'rb') as f:\n",
    "        #     data = pickle.load(f)\n",
    "\n",
    "        # for x in data:\n",
    "        #     length += len(data[x])\n",
    "        # return length\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.x[index], self.y[index]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78602414",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-23T06:05:20.181033Z",
     "iopub.status.busy": "2022-05-23T06:05:20.180809Z",
     "iopub.status.idle": "2022-05-23T06:05:20.197269Z",
     "shell.execute_reply": "2022-05-23T06:05:20.196667Z"
    },
    "papermill": {
     "duration": 0.057915,
     "end_time": "2022-05-23T06:05:20.198966",
     "exception": false,
     "start_time": "2022-05-23T06:05:20.141051",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "IMAGE_HEIGHT = 720\n",
    "IMAGE_WIDTH = 800\n",
    "IMAGE_CHANNEL = 1\n",
    "NUM_FRAMES = 25\n",
    "NUM_CLASSES = 60\n",
    "\n",
    "\n",
    "\n",
    "train_inputs =[] #x\n",
    "train_classes = [] #y\n",
    "val_inputs = []\n",
    "val_classes = []\n",
    "\n",
    "def transform_data(x, mean, std):\n",
    "    \n",
    "    transform =  ApplyTransformToKey(\n",
    "        key=\"video\",\n",
    "        transform=Compose(\n",
    "            [\n",
    "\n",
    "                Lambda(lambda x: x.permute(1,0,2,3)),#(frames(depth), channel, height, width) -> (channel, frames(depth), height, width)\n",
    "\n",
    "                UniformTemporalSubsample(NUM_FRAMES),\n",
    "                Lambda(lambda x: x.permute(1,0,2,3)),#(frames(depth), channel, height, width)\n",
    "                Lambda(lambda x: x/255.0),\n",
    "                \n",
    "                Normalize((mean,), (std,)),\n",
    "\n",
    "                CenterCrop([720,854]),\n",
    "                Resize([480,570]),\n",
    "                Lambda(lambda x: x.permute(1,0,2,3)),#(channel, frames(depth), height, width)\n",
    "\n",
    "            ]\n",
    "\n",
    "        ),\n",
    "    )\n",
    "    \n",
    "    return transform(x)\n",
    "\n",
    "\n",
    "def load_dataloaders(batch_size,start,end):\n",
    "    with open('../input/signdataset/sign/MSSL_Train_Set/TRAIN/MSSL_TRAIN_SET_GT.pkl', 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "\n",
    "\n",
    "# keys are files so iterate only limited files due to memory limitations.\n",
    "    for key in list(data.keys())[start:end]:\n",
    "        filename = key\n",
    "        print(\"file\",filename)\n",
    "        video = EncodedVideo.from_path(\"../input/signdataset/sign/MSSL_Train_Set/TRAIN/MSSL_TRAIN_SET_VIDEOS_ELAN/\"+filename+\".mp4\")\n",
    "    # file functions\n",
    "\n",
    "        for x in data[key]:\n",
    "            train_classes.append(x[0])\n",
    "            start_time = x[1]\n",
    "            end_time = x[2]\n",
    "   #give path\n",
    "            \n",
    "    \n",
    "            \n",
    "            \n",
    "            video_data = video.get_clip(start_sec=float(start_time)/1000.0, end_sec=float(end_time)/1000.0)\n",
    "            #print(video_data[\"video\"].shape)\n",
    "\n",
    "            \n",
    "            video_data[\"video\"] = Grayscale(num_output_channels=1)((video_data[\"video\"]).permute(1,0,2,3))\n",
    "#             video_data[\"video\"] = video_data[\"video\"]/255\n",
    "            #print(video_data[\"video\"].shape)\n",
    "            \n",
    "            std, mean = torch.std_mean(video_data[\"video\"])\n",
    "            std = std/255.0\n",
    "            mean = mean/255.0\n",
    "        \n",
    "            \n",
    "            \n",
    "            video_data = transform_data( video_data, mean, std)\n",
    "\n",
    "        # Move the inputs to the desired device\n",
    "            train_inputs.append(video_data[\"video\"])\n",
    "\n",
    "    signds = SignDataset(train_inputs, train_classes)\n",
    "    trainlen = int(len(signds)*0.8)\n",
    "    torch.manual_seed(0)\n",
    "    \n",
    "    train_set, val_test_set = torch.utils.data.random_split(signds, [trainlen, len(signds)-trainlen])\n",
    "    trainloader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "    \n",
    "    vallen= int(len(val_test_set)*0.8)\n",
    "    val_set, test_set = torch.utils.data.random_split(val_test_set, [vallen, len(val_test_set)-vallen ])\n",
    "    valloader = DataLoader(val_set, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "    testloader = DataLoader(test_set, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "    return trainloader, valloader, testloader \n",
    "        \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86f2bffc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-23T06:05:20.275132Z",
     "iopub.status.busy": "2022-05-23T06:05:20.274747Z",
     "iopub.status.idle": "2022-05-23T06:05:20.314925Z",
     "shell.execute_reply": "2022-05-23T06:05:20.314277Z"
    },
    "papermill": {
     "duration": 0.08026,
     "end_time": "2022-05-23T06:05:20.316510",
     "exception": false,
     "start_time": "2022-05-23T06:05:20.236250",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class conv_3d(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(conv_3d, self).__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv3d(1, 64, kernel_size=5, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2)))\n",
    "        \n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv3d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2)))\n",
    "        \n",
    "\n",
    "        self._features = nn.Sequential(\n",
    "            self.conv1,\n",
    "            self.conv2\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self._features(x)# batch size, num channels,frames,  height, width\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    def __init__(self, in_planes, out_planes, dropRate=0.0):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.bn1 = nn.BatchNorm2d(in_planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv1 = nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=1,\n",
    "                               padding=1, bias=False)\n",
    "        self.droprate = dropRate\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(self.relu(self.bn1(x)))\n",
    "        if self.droprate > 0:\n",
    "            out = F.dropout(out, p=self.droprate, training=self.training)\n",
    "        return torch.cat([x, out], 1)\n",
    "\n",
    "class BottleneckBlock(nn.Module):\n",
    "    def __init__(self, in_planes, out_planes, dropRate=0.0):\n",
    "        super(BottleneckBlock, self).__init__()\n",
    "        inter_planes = out_planes * 4\n",
    "        self.bn1 = nn.BatchNorm2d(in_planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv1 = nn.Conv2d(in_planes, inter_planes, kernel_size=1, stride=1,\n",
    "                               padding=0, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(inter_planes)\n",
    "        self.conv2 = nn.Conv2d(inter_planes, out_planes, kernel_size=3, stride=1,\n",
    "                               padding=1, bias=False)\n",
    "        self.droprate = dropRate\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(self.relu(self.bn1(x)))\n",
    "        if self.droprate > 0:\n",
    "            out = F.dropout(out, p=self.droprate, inplace=False, training=self.training)\n",
    "        out = self.conv2(self.relu(self.bn2(out)))\n",
    "        if self.droprate > 0:\n",
    "            out = F.dropout(out, p=self.droprate, inplace=False, training=self.training)\n",
    "        return torch.cat([x, out], 1)\n",
    "\n",
    "class TransitionBlock(nn.Module):\n",
    "    def __init__(self, in_planes, out_planes, dropRate=0.0):\n",
    "        super(TransitionBlock, self).__init__()\n",
    "        self.bn1 = nn.BatchNorm2d(in_planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv1 = nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=1,\n",
    "                               padding=0, bias=False)\n",
    "        self.droprate = dropRate\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(self.relu(self.bn1(x)))\n",
    "        if self.droprate > 0:\n",
    "            out = F.dropout(out, p=self.droprate, inplace=False, training=self.training)\n",
    "        return F.avg_pool2d(out, 2)\n",
    "    \n",
    "    \n",
    "class DenseBlock(nn.Module):\n",
    "    def __init__(self, nb_layers, in_planes, growth_rate, block, dropRate=0.0):\n",
    "        super(DenseBlock, self).__init__()\n",
    "        self.layer = self._make_layer(block, in_planes, growth_rate, nb_layers, dropRate)\n",
    "    def _make_layer(self, block, in_planes, growth_rate, nb_layers, dropRate):\n",
    "        layers = []\n",
    "        for i in range(nb_layers):\n",
    "            layers.append(block(in_planes+i*growth_rate, growth_rate, dropRate))\n",
    "        return nn.Sequential(*layers)\n",
    "    def forward(self, x):\n",
    "        return self.layer(x)\n",
    "\n",
    "class DenseNet3(nn.Module):\n",
    "    def __init__(self, depth=10, num_classes=60, growth_rate=12,\n",
    "                 reduction=0.5, bottleneck=True, dropRate=0.4):\n",
    "        super(DenseNet3, self).__init__()\n",
    "        in_planes = 2 * growth_rate\n",
    "        n = (depth - 4) / 3\n",
    "        if bottleneck == True:\n",
    "            n = n/2\n",
    "            block = BottleneckBlock\n",
    "        else:\n",
    "            block = BasicBlock\n",
    "        n = int(n)\n",
    "        # 1st conv before any dense block\n",
    "        self.conv1 = nn.Conv2d(128, in_planes, kernel_size=3, stride=1,\n",
    "                               padding=1, bias=False)\n",
    "        # 1st block\n",
    "        self.block1 = DenseBlock(n, in_planes, growth_rate, block, dropRate)\n",
    "        in_planes = int(in_planes+n*growth_rate)\n",
    "        self.trans1 = TransitionBlock(in_planes, int(math.floor(in_planes*reduction)), dropRate=dropRate)\n",
    "        in_planes = int(math.floor(in_planes*reduction))\n",
    "        # 2nd block\n",
    "        self.block2 = DenseBlock(n, in_planes, growth_rate, block, dropRate)\n",
    "        in_planes = int(in_planes+n*growth_rate)\n",
    "        self.trans2 = TransitionBlock(in_planes, int(math.floor(in_planes*reduction)), dropRate=dropRate)\n",
    "        in_planes = int(math.floor(in_planes*reduction))\n",
    "        # 3rd block\n",
    "        self.block3 = DenseBlock(n, in_planes, growth_rate, block, dropRate)\n",
    "        in_planes = int(in_planes+n*growth_rate)\n",
    "        # global average pooling and classifier\n",
    "        self.bn1 = nn.BatchNorm2d(in_planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.fc = nn.Linear(in_planes, num_classes)\n",
    "        self.in_planes = in_planes\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                m.bias.data.zero_()\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        \n",
    "        out = self.trans1(self.block1(out))\n",
    "        \n",
    "        out = self.trans2(self.block2(out))\n",
    "        \n",
    "        out = self.block3(out)\n",
    "        \n",
    "        out = self.relu(self.bn1(out))\n",
    "        \n",
    "        out = F.avg_pool2d(out, 3)\n",
    "        \n",
    "        \n",
    "        return out\n",
    "        \n",
    "        \n",
    "def flatten(t):\n",
    "    t = t.reshape(1, -1)\n",
    "    t = t.squeeze()\n",
    "    return t\n",
    "  \n",
    "class TimeDistributed(nn.Module):\n",
    "    def __init__(self, module, batch_first=True):\n",
    "        super(TimeDistributed, self).__init__()\n",
    "        self.module = module\n",
    "        self.batch_first = batch_first\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = x.permute(0,1,3,4,2)# (batch, channels, height, width, frames)\n",
    "        tList = [flatten(self.module(m)) for m in torch.unbind(x, dim=4) ]\n",
    "        y = torch.stack(tList, dim=0)\n",
    "        # We have to reshape Y\n",
    "        if self.batch_first:\n",
    "            y = y.contiguous().view(x.size(0), x.size(4),-1)  # (samples, timesteps, output_size)\n",
    "            \n",
    "        else:\n",
    "            y = y.view(x.size(4), x.size(0), -1)  # (timesteps, samples, output_size)\n",
    "        return y\n",
    "    \n",
    "\n",
    "               \n",
    "        \n",
    "\n",
    "\n",
    "class lstm(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(lstm, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #print(inputs.shape)\n",
    "        # Run through LSTM layer\n",
    "        out, _ = self.lstm(x)\n",
    "        out = out[:,-1,:]\n",
    "        out = out.view(x.size(0),-1)\n",
    "        return out\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c5cd1bd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-23T06:05:20.391233Z",
     "iopub.status.busy": "2022-05-23T06:05:20.390810Z",
     "iopub.status.idle": "2022-05-23T06:05:20.414764Z",
     "shell.execute_reply": "2022-05-23T06:05:20.414126Z"
    },
    "papermill": {
     "duration": 0.063297,
     "end_time": "2022-05-23T06:05:20.416329",
     "exception": false,
     "start_time": "2022-05-23T06:05:20.353032",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def test(model, device, loader, mode=\"Validate\"):\n",
    "    \n",
    "    \n",
    "    model.eval()\n",
    "\n",
    "    correct = 0\n",
    "    num_samples = 0\n",
    "    \n",
    "        \n",
    "    for batch_idx, (data, target) in enumerate(loader):\n",
    "        with torch.no_grad():    \n",
    "            data = data.to(device)\n",
    "            target = (target).to(device)\n",
    "\n",
    "            output = model(data.half())  \n",
    "            \n",
    "            pred = output.max(1, keepdim=True)[1]# get the index of the max log-probability\n",
    "            \n",
    "            num_samples += pred.shape[0]\n",
    "            \n",
    "#             print(\"num_samples:\", num_samples)\n",
    "            #print(torch.sum(pred==target))\n",
    "            correct += (pred == target).sum().item()\n",
    "            #print(\"correct\", correct)\n",
    "\n",
    "    acc = 100.0 * correct / num_samples\n",
    "    \n",
    "    print('{} Accuracy: {}/{} ({:.0f}%)'.format(\n",
    "                mode,correct, num_samples,\n",
    "                100. * correct / num_samples, acc))\n",
    "    \n",
    "def trainonval(model, device,validloader, optimizer, scheduler, criterion, epochs):\n",
    "\n",
    "    \n",
    "    model.train()\n",
    "    optimizer.param_groups[0]['lr'] = 1e-2\n",
    "    print(\"Training on Validation Set starts\")\n",
    "    for epoch in range(epochs):\n",
    "        correct = 0\n",
    "        num_samples = 0\n",
    "        train_loss = 0\n",
    "        \n",
    "        for batch_idx, (data, target) in enumerate(validloader):\n",
    "            \n",
    "            data = data.to(device)\n",
    "            target = target.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data.half())\n",
    "            \n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            \n",
    "            pred = (output.data).max(1, keepdim=True)[1]# get the index of the max log-probability\n",
    "            num_samples += pred.shape[0]\n",
    "            correct += torch.sum(pred.data==target)\n",
    "            \n",
    "        scheduler.step()\n",
    "        print(scheduler.get_last_lr())\n",
    "        train_loss /= num_samples\n",
    "        \n",
    "        if (100 * correct / num_samples) >= 90:\n",
    "            \n",
    "            print('Epoch: {} , Training Accuracy on Val set: {}/{} ({:.0f}%) Training Loss: {:.6f}'.format(\n",
    "                epoch+1, correct, num_samples,100. * correct / num_samples, train_loss))\n",
    "            test(model, device, testloader, mode = \"Test after Training on validation set\")\n",
    "                \n",
    "            return model, optimizer\n",
    "            \n",
    "    \n",
    "        print('Epoch: {} , Training Accuracy: {}/{} ({:.0f}%) Training Loss: {:.6f}'.format(\n",
    "                epoch+1, correct, num_samples,\n",
    "                100. * correct / num_samples, train_loss))\n",
    "        \n",
    "    return model, optimizer\n",
    "\n",
    "def train(model, device, train_loader,validloader,testloader, optimizer,scheduler,criterion, epochs):\n",
    "    print(\"Train start\")\n",
    "    breakout = False\n",
    "    model.half()\n",
    "    model.cuda()\n",
    "    \n",
    "    model.train()\n",
    "\n",
    "    \n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        correct = 0\n",
    "        num_samples = 0\n",
    "        train_loss = 0\n",
    "        \n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            \n",
    "            data = data.to(device)\n",
    "            target = target.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data.half())\n",
    "            \n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            \n",
    "            pred = output.max(1, keepdim=True)[1]# get the index of the max log-probability\n",
    "            num_samples += pred.shape[0]\n",
    "            correct += torch.sum(pred==target)\n",
    "            \n",
    "            \n",
    "        scheduler.step()\n",
    "        print(\"lr:\",optimizer.param_groups[0]['lr'])\n",
    "        \n",
    "        train_loss /= num_samples\n",
    "        \n",
    "        if (100 * correct / num_samples) >= 95:\n",
    "            \n",
    "            print('Epoch: {} , Training Accuracy: {}/{} ({:.0f}%) Training Loss: {:.6f}'.format(\n",
    "                epoch+1, correct, num_samples,100. * correct / num_samples, train_loss))\n",
    "            \n",
    "            test(model,device,validloader, mode = \"Validating\")\n",
    "            test(model, device, testloader, mode = \"Test before Training on validation set\")\n",
    "            model, optimizer = trainonval(model, device, validloader, optimizer, scheduler, criterion, epochs)\n",
    "            test(model, device, testloader, mode = \"Test after training on validation set\")\n",
    "            \n",
    "            \n",
    "            \n",
    "            torch.save({\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict()}, \"./model_optimizer.pt\")\n",
    "            \n",
    "            breakout = True\n",
    "            break\n",
    "            \n",
    "            \n",
    "            \n",
    "       \n",
    "        \n",
    "\n",
    "        print('Epoch: {} , Training Accuracy: {}/{} ({:.0f}%) Training Loss: {:.6f}'.format(\n",
    "                epoch+1, correct, num_samples,\n",
    "                100. * correct / num_samples, train_loss))\n",
    "        if (((epoch+1)%5) == 0) :\n",
    "            test(model,device,validloader)\n",
    "            model.train()\n",
    "            \n",
    "    if breakout:\n",
    "            print(\"breakout\")\n",
    "            return\n",
    "    \n",
    "    \n",
    "    \n",
    "    model, optimizer = trainonval(model, device, validloader, optimizer,scheduler, criterion, epochs)\n",
    "    test(model, device, testloader, mode= \"test set \")\n",
    "    \n",
    "    \n",
    "        \n",
    "    torch.save({\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict()}, \"./model_optimizer.pt\")\n",
    "    \n",
    "    \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a2ae673",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-23T06:05:20.492622Z",
     "iopub.status.busy": "2022-05-23T06:05:20.492068Z",
     "iopub.status.idle": "2022-05-23T06:05:20.759211Z",
     "shell.execute_reply": "2022-05-23T06:05:20.758487Z"
    },
    "papermill": {
     "duration": 0.307995,
     "end_time": "2022-05-23T06:05:20.761491",
     "exception": false,
     "start_time": "2022-05-23T06:05:20.453496",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.0000e-02.\n",
      "Adjusting learning rate of group 1 to 1.0000e-02.\n",
      "Adjusting learning rate of group 2 to 1.0000e-02.\n",
      "Adjusting learning rate of group 3 to 1.0000e-02.\n"
     ]
    }
   ],
   "source": [
    "n_classes = 60\n",
    "\n",
    "\n",
    "model = nn.Sequential(OrderedDict([\n",
    "    ('frontend', conv_3d()),\n",
    "    ('features', TimeDistributed(DenseNet3())),\n",
    "    ('backend', lstm(input_size=2673, hidden_size=1336)),\n",
    "    ('fc', nn.Sequential( nn.Dropout(p=0.5), nn.Linear(1336, 60)))\n",
    "]))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# specify loss function (categorical cross-entropy)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# specify optimizer and learning rate\n",
    "optimizer = optim.SGD(\n",
    "    [\n",
    "        {\"params\": model.fc.parameters(), \"lr\": 1e-2},\n",
    "        {\"params\": model.features.parameters(), \"lr\": 1e-2},\n",
    "        {\"params\": model.backend.parameters(), \"lr\": 1e-2},\n",
    "        {\"params\": model.frontend.parameters(), \"lr\": 1e-2},\n",
    "  ],\n",
    "  momentum = 0.9\n",
    ")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=15, gamma=0.1, verbose = True)\n",
    "# state = torch.load(\"../input/sign-classification/model_optimizer.pt\")\n",
    "# model.load_state_dict(state['model_state_dict'])\n",
    "# model.half()\n",
    "# model.cuda()\n",
    "# optimizer.load_state_dict(state['optimizer_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "245dbc3b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-23T06:05:20.837266Z",
     "iopub.status.busy": "2022-05-23T06:05:20.836710Z",
     "iopub.status.idle": "2022-05-23T06:08:03.257049Z",
     "shell.execute_reply": "2022-05-23T06:08:03.256322Z"
    },
    "papermill": {
     "duration": 162.460442,
     "end_time": "2022-05-23T06:08:03.259090",
     "exception": false,
     "start_time": "2022-05-23T06:05:20.798648",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file p06_n019\n",
      "file p06_n007\n",
      "file p01_n053\n",
      "file p04_n074\n",
      "file p05_n077\n",
      "file p05_n027\n",
      "file p05_n022\n",
      "file p01_n110\n",
      "file p06_n036\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "trainloader, valloader, testloader = load_dataloaders(batch_size=4,start=start, end=end)#73 not included \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35cdc4a7",
   "metadata": {
    "papermill": {
     "duration": 0.039708,
     "end_time": "2022-05-23T06:08:03.338707",
     "exception": false,
     "start_time": "2022-05-23T06:08:03.298999",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d7fd1f73",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-23T06:08:03.418749Z",
     "iopub.status.busy": "2022-05-23T06:08:03.418505Z",
     "iopub.status.idle": "2022-05-23T06:08:03.423676Z",
     "shell.execute_reply": "2022-05-23T06:08:03.422876Z"
    },
    "papermill": {
     "duration": 0.048758,
     "end_time": "2022-05-23T06:08:03.426915",
     "exception": false,
     "start_time": "2022-05-23T06:08:03.378157",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of model parameters: 21793682\n"
     ]
    }
   ],
   "source": [
    "print('Number of model parameters: {}'.format(sum([p.data.nelement() for p in model.parameters()])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e4a7336d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-23T06:08:03.508645Z",
     "iopub.status.busy": "2022-05-23T06:08:03.508411Z",
     "iopub.status.idle": "2022-05-23T06:33:52.111768Z",
     "shell.execute_reply": "2022-05-23T06:33:52.110910Z"
    },
    "papermill": {
     "duration": 1548.645822,
     "end_time": "2022-05-23T06:33:52.113712",
     "exception": false,
     "start_time": "2022-05-23T06:08:03.467890",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train start\n",
      "Adjusting learning rate of group 0 to 1.0000e-02.\n",
      "Adjusting learning rate of group 1 to 1.0000e-02.\n",
      "Adjusting learning rate of group 2 to 1.0000e-02.\n",
      "Adjusting learning rate of group 3 to 1.0000e-02.\n",
      "lr: 0.01\n",
      "Epoch: 1 , Training Accuracy: 27/152 (18%) Training Loss: 1.005076\n",
      "Adjusting learning rate of group 0 to 1.0000e-02.\n",
      "Adjusting learning rate of group 1 to 1.0000e-02.\n",
      "Adjusting learning rate of group 2 to 1.0000e-02.\n",
      "Adjusting learning rate of group 3 to 1.0000e-02.\n",
      "lr: 0.01\n",
      "Epoch: 2 , Training Accuracy: 38/152 (25%) Training Loss: 0.967324\n",
      "Adjusting learning rate of group 0 to 1.0000e-02.\n",
      "Adjusting learning rate of group 1 to 1.0000e-02.\n",
      "Adjusting learning rate of group 2 to 1.0000e-02.\n",
      "Adjusting learning rate of group 3 to 1.0000e-02.\n",
      "lr: 0.01\n",
      "Epoch: 3 , Training Accuracy: 42/152 (28%) Training Loss: 0.912289\n",
      "Adjusting learning rate of group 0 to 1.0000e-02.\n",
      "Adjusting learning rate of group 1 to 1.0000e-02.\n",
      "Adjusting learning rate of group 2 to 1.0000e-02.\n",
      "Adjusting learning rate of group 3 to 1.0000e-02.\n",
      "lr: 0.01\n",
      "Epoch: 4 , Training Accuracy: 57/152 (38%) Training Loss: 0.837942\n",
      "Adjusting learning rate of group 0 to 1.0000e-02.\n",
      "Adjusting learning rate of group 1 to 1.0000e-02.\n",
      "Adjusting learning rate of group 2 to 1.0000e-02.\n",
      "Adjusting learning rate of group 3 to 1.0000e-02.\n",
      "lr: 0.01\n",
      "Epoch: 5 , Training Accuracy: 65/152 (43%) Training Loss: 0.772365\n",
      "Validate Accuracy: 3/31 (10%)\n",
      "Adjusting learning rate of group 0 to 1.0000e-02.\n",
      "Adjusting learning rate of group 1 to 1.0000e-02.\n",
      "Adjusting learning rate of group 2 to 1.0000e-02.\n",
      "Adjusting learning rate of group 3 to 1.0000e-02.\n",
      "lr: 0.01\n",
      "Epoch: 6 , Training Accuracy: 58/152 (38%) Training Loss: 0.720600\n",
      "Adjusting learning rate of group 0 to 1.0000e-02.\n",
      "Adjusting learning rate of group 1 to 1.0000e-02.\n",
      "Adjusting learning rate of group 2 to 1.0000e-02.\n",
      "Adjusting learning rate of group 3 to 1.0000e-02.\n",
      "lr: 0.01\n",
      "Epoch: 7 , Training Accuracy: 69/152 (45%) Training Loss: 0.663311\n",
      "Adjusting learning rate of group 0 to 1.0000e-02.\n",
      "Adjusting learning rate of group 1 to 1.0000e-02.\n",
      "Adjusting learning rate of group 2 to 1.0000e-02.\n",
      "Adjusting learning rate of group 3 to 1.0000e-02.\n",
      "lr: 0.01\n",
      "Epoch: 8 , Training Accuracy: 70/152 (46%) Training Loss: 0.608289\n",
      "Adjusting learning rate of group 0 to 1.0000e-02.\n",
      "Adjusting learning rate of group 1 to 1.0000e-02.\n",
      "Adjusting learning rate of group 2 to 1.0000e-02.\n",
      "Adjusting learning rate of group 3 to 1.0000e-02.\n",
      "lr: 0.01\n",
      "Epoch: 9 , Training Accuracy: 70/152 (46%) Training Loss: 0.586837\n",
      "Adjusting learning rate of group 0 to 1.0000e-02.\n",
      "Adjusting learning rate of group 1 to 1.0000e-02.\n",
      "Adjusting learning rate of group 2 to 1.0000e-02.\n",
      "Adjusting learning rate of group 3 to 1.0000e-02.\n",
      "lr: 0.01\n",
      "Epoch: 10 , Training Accuracy: 90/152 (59%) Training Loss: 0.524610\n",
      "Validate Accuracy: 11/31 (35%)\n",
      "Adjusting learning rate of group 0 to 1.0000e-02.\n",
      "Adjusting learning rate of group 1 to 1.0000e-02.\n",
      "Adjusting learning rate of group 2 to 1.0000e-02.\n",
      "Adjusting learning rate of group 3 to 1.0000e-02.\n",
      "lr: 0.01\n",
      "Epoch: 11 , Training Accuracy: 71/152 (47%) Training Loss: 0.521844\n",
      "Adjusting learning rate of group 0 to 1.0000e-02.\n",
      "Adjusting learning rate of group 1 to 1.0000e-02.\n",
      "Adjusting learning rate of group 2 to 1.0000e-02.\n",
      "Adjusting learning rate of group 3 to 1.0000e-02.\n",
      "lr: 0.01\n",
      "Epoch: 12 , Training Accuracy: 101/152 (66%) Training Loss: 0.429217\n",
      "Adjusting learning rate of group 0 to 1.0000e-02.\n",
      "Adjusting learning rate of group 1 to 1.0000e-02.\n",
      "Adjusting learning rate of group 2 to 1.0000e-02.\n",
      "Adjusting learning rate of group 3 to 1.0000e-02.\n",
      "lr: 0.01\n",
      "Epoch: 13 , Training Accuracy: 115/152 (76%) Training Loss: 0.384827\n",
      "Adjusting learning rate of group 0 to 1.0000e-02.\n",
      "Adjusting learning rate of group 1 to 1.0000e-02.\n",
      "Adjusting learning rate of group 2 to 1.0000e-02.\n",
      "Adjusting learning rate of group 3 to 1.0000e-02.\n",
      "lr: 0.01\n",
      "Epoch: 14 , Training Accuracy: 88/152 (58%) Training Loss: 0.410400\n",
      "Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "Adjusting learning rate of group 1 to 1.0000e-03.\n",
      "Adjusting learning rate of group 2 to 1.0000e-03.\n",
      "Adjusting learning rate of group 3 to 1.0000e-03.\n",
      "lr: 0.001\n",
      "Epoch: 15 , Training Accuracy: 98/152 (64%) Training Loss: 0.393886\n",
      "Validate Accuracy: 14/31 (45%)\n",
      "Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "Adjusting learning rate of group 1 to 1.0000e-03.\n",
      "Adjusting learning rate of group 2 to 1.0000e-03.\n",
      "Adjusting learning rate of group 3 to 1.0000e-03.\n",
      "lr: 0.001\n",
      "Epoch: 16 , Training Accuracy: 129/152 (85%) Training Loss: 0.271529\n",
      "Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "Adjusting learning rate of group 1 to 1.0000e-03.\n",
      "Adjusting learning rate of group 2 to 1.0000e-03.\n",
      "Adjusting learning rate of group 3 to 1.0000e-03.\n",
      "lr: 0.001\n",
      "Epoch: 17 , Training Accuracy: 130/152 (86%) Training Loss: 0.222499\n",
      "Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "Adjusting learning rate of group 1 to 1.0000e-03.\n",
      "Adjusting learning rate of group 2 to 1.0000e-03.\n",
      "Adjusting learning rate of group 3 to 1.0000e-03.\n",
      "lr: 0.001\n",
      "Epoch: 18 , Training Accuracy: 137/152 (90%) Training Loss: 0.196736\n",
      "Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "Adjusting learning rate of group 1 to 1.0000e-03.\n",
      "Adjusting learning rate of group 2 to 1.0000e-03.\n",
      "Adjusting learning rate of group 3 to 1.0000e-03.\n",
      "lr: 0.001\n",
      "Epoch: 19 , Training Accuracy: 146/152 (96%) Training Loss: 0.164107\n",
      "Validating Accuracy: 18/31 (58%)\n",
      "Test before Training on validation set Accuracy: 2/8 (25%)\n",
      "Training on Validation Set starts\n",
      "Adjusting learning rate of group 0 to 1.0000e-02.\n",
      "Adjusting learning rate of group 1 to 1.0000e-03.\n",
      "Adjusting learning rate of group 2 to 1.0000e-03.\n",
      "Adjusting learning rate of group 3 to 1.0000e-03.\n",
      "[0.01, 0.001, 0.001, 0.001]\n",
      "Epoch: 1 , Training Accuracy: 9/31 (29%) Training Loss: 1.051569\n",
      "Adjusting learning rate of group 0 to 1.0000e-02.\n",
      "Adjusting learning rate of group 1 to 1.0000e-03.\n",
      "Adjusting learning rate of group 2 to 1.0000e-03.\n",
      "Adjusting learning rate of group 3 to 1.0000e-03.\n",
      "[0.01, 0.001, 0.001, 0.001]\n",
      "Epoch: 2 , Training Accuracy: 12/31 (39%) Training Loss: 0.936555\n",
      "Adjusting learning rate of group 0 to 1.0000e-02.\n",
      "Adjusting learning rate of group 1 to 1.0000e-03.\n",
      "Adjusting learning rate of group 2 to 1.0000e-03.\n",
      "Adjusting learning rate of group 3 to 1.0000e-03.\n",
      "[0.01, 0.001, 0.001, 0.001]\n",
      "Epoch: 3 , Training Accuracy: 16/31 (52%) Training Loss: 0.759545\n",
      "Adjusting learning rate of group 0 to 1.0000e-02.\n",
      "Adjusting learning rate of group 1 to 1.0000e-03.\n",
      "Adjusting learning rate of group 2 to 1.0000e-03.\n",
      "Adjusting learning rate of group 3 to 1.0000e-03.\n",
      "[0.01, 0.001, 0.001, 0.001]\n",
      "Epoch: 4 , Training Accuracy: 25/31 (81%) Training Loss: 0.555774\n",
      "Adjusting learning rate of group 0 to 1.0000e-02.\n",
      "Adjusting learning rate of group 1 to 1.0000e-03.\n",
      "Adjusting learning rate of group 2 to 1.0000e-03.\n",
      "Adjusting learning rate of group 3 to 1.0000e-03.\n",
      "[0.01, 0.001, 0.001, 0.001]\n",
      "Epoch: 5 , Training Accuracy: 27/31 (87%) Training Loss: 0.469837\n",
      "Adjusting learning rate of group 0 to 1.0000e-02.\n",
      "Adjusting learning rate of group 1 to 1.0000e-03.\n",
      "Adjusting learning rate of group 2 to 1.0000e-03.\n",
      "Adjusting learning rate of group 3 to 1.0000e-03.\n",
      "[0.01, 0.001, 0.001, 0.001]\n",
      "Epoch: 6 , Training Accuracy: 27/31 (87%) Training Loss: 0.311279\n",
      "Adjusting learning rate of group 0 to 1.0000e-02.\n",
      "Adjusting learning rate of group 1 to 1.0000e-03.\n",
      "Adjusting learning rate of group 2 to 1.0000e-03.\n",
      "Adjusting learning rate of group 3 to 1.0000e-03.\n",
      "[0.01, 0.001, 0.001, 0.001]\n",
      "Epoch: 7 , Training Accuracy: 27/31 (87%) Training Loss: 0.377146\n",
      "Adjusting learning rate of group 0 to 1.0000e-02.\n",
      "Adjusting learning rate of group 1 to 1.0000e-03.\n",
      "Adjusting learning rate of group 2 to 1.0000e-03.\n",
      "Adjusting learning rate of group 3 to 1.0000e-03.\n",
      "[0.01, 0.001, 0.001, 0.001]\n",
      "Epoch: 8 , Training Accuracy on Val set: 30/31 (97%) Training Loss: 0.323955\n",
      "Test after Training on validation set Accuracy: 4/8 (50%)\n",
      "Test after training on validation set Accuracy: 4/8 (50%)\n",
      "breakout\n"
     ]
    }
   ],
   "source": [
    "train(model,device,trainloader,valloader, testloader,optimizer,scheduler,criterion,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb5ea8a",
   "metadata": {
    "papermill": {
     "duration": 0.052067,
     "end_time": "2022-05-23T06:33:52.217901",
     "exception": false,
     "start_time": "2022-05-23T06:33:52.165834",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bcf5ec46",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-23T06:33:52.322471Z",
     "iopub.status.busy": "2022-05-23T06:33:52.322175Z",
     "iopub.status.idle": "2022-05-23T06:33:52.326107Z",
     "shell.execute_reply": "2022-05-23T06:33:52.325465Z"
    },
    "papermill": {
     "duration": 0.058326,
     "end_time": "2022-05-23T06:33:52.327792",
     "exception": false,
     "start_time": "2022-05-23T06:33:52.269466",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    " #test(model, device, testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "68942435",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-23T06:33:52.432105Z",
     "iopub.status.busy": "2022-05-23T06:33:52.431562Z",
     "iopub.status.idle": "2022-05-23T06:33:52.434985Z",
     "shell.execute_reply": "2022-05-23T06:33:52.434202Z"
    },
    "papermill": {
     "duration": 0.057759,
     "end_time": "2022-05-23T06:33:52.436866",
     "exception": false,
     "start_time": "2022-05-23T06:33:52.379107",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#from 21 15 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9daadba2",
   "metadata": {
    "papermill": {
     "duration": 0.051314,
     "end_time": "2022-05-23T06:33:52.539440",
     "exception": false,
     "start_time": "2022-05-23T06:33:52.488126",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1744.988216,
   "end_time": "2022-05-23T06:33:55.166574",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-05-23T06:04:50.178358",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
